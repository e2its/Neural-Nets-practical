{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset ARM: Analisis comparativo de MLPs,CNNs y RNNs para datos basados en Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "## Checking tensorflow backend engine\n",
    "import tensorflow as tf\n",
    "message = tf.constant('Hello world!')\n",
    "session = tf.Session()\n",
    "session.run(message)\n",
    "import keras.backend as K\n",
    "print(K.epsilon())\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical, plot_model\n",
    "\n",
    "from numpy import argmax,reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pandas.read_csv(\"https://raw.githubusercontent.com/e2its/datasets/master/ARM-Metric-train-TS.csv\",encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pandas.read_csv(\"https://raw.githubusercontent.com/e2its/datasets/master/ARM-Metric-test-TS.csv\",encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>bending</td>\n",
       "      <td>34.249340</td>\n",
       "      <td>0.431254</td>\n",
       "      <td>16.755905</td>\n",
       "      <td>0.733249</td>\n",
       "      <td>23.503262</td>\n",
       "      <td>34.249340</td>\n",
       "      <td>0.431254</td>\n",
       "      <td>16.755905</td>\n",
       "      <td>0.733249</td>\n",
       "      <td>23.503262</td>\n",
       "      <td>...</td>\n",
       "      <td>34.030624</td>\n",
       "      <td>0.428355</td>\n",
       "      <td>16.659172</td>\n",
       "      <td>0.727505</td>\n",
       "      <td>23.361322</td>\n",
       "      <td>33.958319</td>\n",
       "      <td>0.427648</td>\n",
       "      <td>16.626693</td>\n",
       "      <td>0.726028</td>\n",
       "      <td>23.312530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cyclin</td>\n",
       "      <td>36.743073</td>\n",
       "      <td>2.691047</td>\n",
       "      <td>16.397729</td>\n",
       "      <td>2.990645</td>\n",
       "      <td>17.391611</td>\n",
       "      <td>36.743073</td>\n",
       "      <td>2.691047</td>\n",
       "      <td>16.397729</td>\n",
       "      <td>2.990645</td>\n",
       "      <td>17.391611</td>\n",
       "      <td>...</td>\n",
       "      <td>36.514153</td>\n",
       "      <td>2.671655</td>\n",
       "      <td>16.289588</td>\n",
       "      <td>2.972231</td>\n",
       "      <td>17.278699</td>\n",
       "      <td>36.436510</td>\n",
       "      <td>2.667201</td>\n",
       "      <td>16.252897</td>\n",
       "      <td>2.965306</td>\n",
       "      <td>17.244941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lyin</td>\n",
       "      <td>39.845100</td>\n",
       "      <td>0.342937</td>\n",
       "      <td>7.264530</td>\n",
       "      <td>0.580750</td>\n",
       "      <td>9.248505</td>\n",
       "      <td>39.845100</td>\n",
       "      <td>0.342937</td>\n",
       "      <td>7.264530</td>\n",
       "      <td>0.580750</td>\n",
       "      <td>9.248505</td>\n",
       "      <td>...</td>\n",
       "      <td>39.596826</td>\n",
       "      <td>0.341302</td>\n",
       "      <td>7.222859</td>\n",
       "      <td>0.578865</td>\n",
       "      <td>9.176209</td>\n",
       "      <td>39.513958</td>\n",
       "      <td>0.340598</td>\n",
       "      <td>7.208963</td>\n",
       "      <td>0.578144</td>\n",
       "      <td>9.152296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sittin</td>\n",
       "      <td>41.743949</td>\n",
       "      <td>0.401680</td>\n",
       "      <td>14.860580</td>\n",
       "      <td>0.749794</td>\n",
       "      <td>16.095726</td>\n",
       "      <td>41.743949</td>\n",
       "      <td>0.401680</td>\n",
       "      <td>14.860580</td>\n",
       "      <td>0.749794</td>\n",
       "      <td>16.095726</td>\n",
       "      <td>...</td>\n",
       "      <td>41.489445</td>\n",
       "      <td>0.399241</td>\n",
       "      <td>14.768017</td>\n",
       "      <td>0.743606</td>\n",
       "      <td>16.006578</td>\n",
       "      <td>41.402354</td>\n",
       "      <td>0.398618</td>\n",
       "      <td>14.736741</td>\n",
       "      <td>0.742544</td>\n",
       "      <td>15.974439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>standin</td>\n",
       "      <td>43.854565</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>14.776667</td>\n",
       "      <td>0.615786</td>\n",
       "      <td>13.701405</td>\n",
       "      <td>43.854565</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>14.776667</td>\n",
       "      <td>0.615786</td>\n",
       "      <td>13.701405</td>\n",
       "      <td>...</td>\n",
       "      <td>43.575974</td>\n",
       "      <td>0.395777</td>\n",
       "      <td>14.687328</td>\n",
       "      <td>0.611673</td>\n",
       "      <td>13.613623</td>\n",
       "      <td>43.483259</td>\n",
       "      <td>0.395032</td>\n",
       "      <td>14.655550</td>\n",
       "      <td>0.610384</td>\n",
       "      <td>13.583375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>walkin</td>\n",
       "      <td>34.424189</td>\n",
       "      <td>4.337724</td>\n",
       "      <td>15.393813</td>\n",
       "      <td>3.200638</td>\n",
       "      <td>16.018848</td>\n",
       "      <td>34.424189</td>\n",
       "      <td>4.337724</td>\n",
       "      <td>15.393813</td>\n",
       "      <td>3.200638</td>\n",
       "      <td>16.018848</td>\n",
       "      <td>...</td>\n",
       "      <td>34.205685</td>\n",
       "      <td>4.311599</td>\n",
       "      <td>15.295110</td>\n",
       "      <td>3.181547</td>\n",
       "      <td>15.921445</td>\n",
       "      <td>34.137645</td>\n",
       "      <td>4.302352</td>\n",
       "      <td>15.266241</td>\n",
       "      <td>3.175534</td>\n",
       "      <td>15.886737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                         \n",
       "bending  34.249340   0.431254  16.755905   0.733249  23.503262    34.249340   \n",
       "cyclin   36.743073   2.691047  16.397729   2.990645  17.391611    36.743073   \n",
       "lyin     39.845100   0.342937   7.264530   0.580750   9.248505    39.845100   \n",
       "sittin   41.743949   0.401680  14.860580   0.749794  16.095726    41.743949   \n",
       "standin  43.854565   0.398300  14.776667   0.615786  13.701405    43.854565   \n",
       "walkin   34.424189   4.337724  15.393813   3.200638  16.018848    34.424189   \n",
       "\n",
       "         var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                        ...                \n",
       "bending     0.431254    16.755905     0.733249    23.503262  ...    34.030624   \n",
       "cyclin      2.691047    16.397729     2.990645    17.391611  ...    36.514153   \n",
       "lyin        0.342937     7.264530     0.580750     9.248505  ...    39.596826   \n",
       "sittin      0.401680    14.860580     0.749794    16.095726  ...    41.489445   \n",
       "standin     0.398300    14.776667     0.615786    13.701405  ...    43.575974   \n",
       "walkin      4.337724    15.393813     3.200638    16.018848  ...    34.205685   \n",
       "\n",
       "         var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                      \n",
       "bending     0.428355    16.659172     0.727505    23.361322    33.958319   \n",
       "cyclin      2.671655    16.289588     2.972231    17.278699    36.436510   \n",
       "lyin        0.341302     7.222859     0.578865     9.176209    39.513958   \n",
       "sittin      0.399241    14.768017     0.743606    16.006578    41.402354   \n",
       "standin     0.395777    14.687328     0.611673    13.613623    43.483259   \n",
       "walkin      4.311599    15.295110     3.181547    15.921445    34.137645   \n",
       "\n",
       "         var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                        \n",
       "bending     0.427648    16.626693     0.726028    23.312530  \n",
       "cyclin      2.667201    16.252897     2.965306    17.244941  \n",
       "lyin        0.340598     7.208963     0.578144     9.152296  \n",
       "sittin      0.398618    14.736741     0.742544    15.974439  \n",
       "standin     0.395032    14.655550     0.610384    13.583375  \n",
       "walkin      4.302352    15.266241     3.175534    15.886737  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('ATYPE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>bending</td>\n",
       "      <td>12.471234</td>\n",
       "      <td>0.563777</td>\n",
       "      <td>7.089369</td>\n",
       "      <td>0.921850</td>\n",
       "      <td>10.430987</td>\n",
       "      <td>12.471234</td>\n",
       "      <td>0.563777</td>\n",
       "      <td>7.089369</td>\n",
       "      <td>0.921850</td>\n",
       "      <td>10.430987</td>\n",
       "      <td>...</td>\n",
       "      <td>12.725044</td>\n",
       "      <td>0.564128</td>\n",
       "      <td>7.181360</td>\n",
       "      <td>0.921409</td>\n",
       "      <td>10.562791</td>\n",
       "      <td>12.807718</td>\n",
       "      <td>0.564301</td>\n",
       "      <td>7.214285</td>\n",
       "      <td>0.921230</td>\n",
       "      <td>10.606611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cyclin</td>\n",
       "      <td>3.820435</td>\n",
       "      <td>1.934903</td>\n",
       "      <td>3.608886</td>\n",
       "      <td>1.710640</td>\n",
       "      <td>3.302717</td>\n",
       "      <td>3.820435</td>\n",
       "      <td>1.934903</td>\n",
       "      <td>3.608886</td>\n",
       "      <td>1.710640</td>\n",
       "      <td>3.302717</td>\n",
       "      <td>...</td>\n",
       "      <td>4.795252</td>\n",
       "      <td>1.939090</td>\n",
       "      <td>3.827658</td>\n",
       "      <td>1.722657</td>\n",
       "      <td>3.567922</td>\n",
       "      <td>5.076117</td>\n",
       "      <td>1.940822</td>\n",
       "      <td>3.894445</td>\n",
       "      <td>1.726250</td>\n",
       "      <td>3.652404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lyin</td>\n",
       "      <td>7.600010</td>\n",
       "      <td>0.377088</td>\n",
       "      <td>3.847469</td>\n",
       "      <td>0.668546</td>\n",
       "      <td>5.113317</td>\n",
       "      <td>7.600010</td>\n",
       "      <td>0.377088</td>\n",
       "      <td>3.847469</td>\n",
       "      <td>0.668546</td>\n",
       "      <td>5.113317</td>\n",
       "      <td>...</td>\n",
       "      <td>8.214017</td>\n",
       "      <td>0.377359</td>\n",
       "      <td>3.881109</td>\n",
       "      <td>0.669349</td>\n",
       "      <td>5.147825</td>\n",
       "      <td>8.407166</td>\n",
       "      <td>0.377567</td>\n",
       "      <td>3.892634</td>\n",
       "      <td>0.669174</td>\n",
       "      <td>5.159684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sittin</td>\n",
       "      <td>4.158324</td>\n",
       "      <td>0.421325</td>\n",
       "      <td>5.207250</td>\n",
       "      <td>0.867719</td>\n",
       "      <td>5.003480</td>\n",
       "      <td>4.158324</td>\n",
       "      <td>0.421325</td>\n",
       "      <td>5.207250</td>\n",
       "      <td>0.867719</td>\n",
       "      <td>5.003480</td>\n",
       "      <td>...</td>\n",
       "      <td>5.276706</td>\n",
       "      <td>0.421247</td>\n",
       "      <td>5.317361</td>\n",
       "      <td>0.866731</td>\n",
       "      <td>5.146924</td>\n",
       "      <td>5.604308</td>\n",
       "      <td>0.421387</td>\n",
       "      <td>5.354299</td>\n",
       "      <td>0.866980</td>\n",
       "      <td>5.193776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>standin</td>\n",
       "      <td>2.628835</td>\n",
       "      <td>0.374164</td>\n",
       "      <td>3.983268</td>\n",
       "      <td>0.722081</td>\n",
       "      <td>3.907701</td>\n",
       "      <td>2.628835</td>\n",
       "      <td>0.374164</td>\n",
       "      <td>3.983268</td>\n",
       "      <td>0.722081</td>\n",
       "      <td>3.907701</td>\n",
       "      <td>...</td>\n",
       "      <td>4.350781</td>\n",
       "      <td>0.374181</td>\n",
       "      <td>4.128552</td>\n",
       "      <td>0.721632</td>\n",
       "      <td>4.046885</td>\n",
       "      <td>4.785235</td>\n",
       "      <td>0.374366</td>\n",
       "      <td>4.178717</td>\n",
       "      <td>0.721755</td>\n",
       "      <td>4.092250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>walkin</td>\n",
       "      <td>4.812406</td>\n",
       "      <td>2.444056</td>\n",
       "      <td>2.916043</td>\n",
       "      <td>1.624244</td>\n",
       "      <td>3.115523</td>\n",
       "      <td>4.812406</td>\n",
       "      <td>2.444056</td>\n",
       "      <td>2.916043</td>\n",
       "      <td>1.624244</td>\n",
       "      <td>3.115523</td>\n",
       "      <td>...</td>\n",
       "      <td>5.519083</td>\n",
       "      <td>2.461158</td>\n",
       "      <td>3.151718</td>\n",
       "      <td>1.638863</td>\n",
       "      <td>3.354381</td>\n",
       "      <td>5.730645</td>\n",
       "      <td>2.466088</td>\n",
       "      <td>3.223939</td>\n",
       "      <td>1.643607</td>\n",
       "      <td>3.430036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                         \n",
       "bending  12.471234   0.563777   7.089369   0.921850  10.430987    12.471234   \n",
       "cyclin    3.820435   1.934903   3.608886   1.710640   3.302717     3.820435   \n",
       "lyin      7.600010   0.377088   3.847469   0.668546   5.113317     7.600010   \n",
       "sittin    4.158324   0.421325   5.207250   0.867719   5.003480     4.158324   \n",
       "standin   2.628835   0.374164   3.983268   0.722081   3.907701     2.628835   \n",
       "walkin    4.812406   2.444056   2.916043   1.624244   3.115523     4.812406   \n",
       "\n",
       "         var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                        ...                \n",
       "bending     0.563777     7.089369     0.921850    10.430987  ...    12.725044   \n",
       "cyclin      1.934903     3.608886     1.710640     3.302717  ...     4.795252   \n",
       "lyin        0.377088     3.847469     0.668546     5.113317  ...     8.214017   \n",
       "sittin      0.421325     5.207250     0.867719     5.003480  ...     5.276706   \n",
       "standin     0.374164     3.983268     0.722081     3.907701  ...     4.350781   \n",
       "walkin      2.444056     2.916043     1.624244     3.115523  ...     5.519083   \n",
       "\n",
       "         var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                      \n",
       "bending     0.564128     7.181360     0.921409    10.562791    12.807718   \n",
       "cyclin      1.939090     3.827658     1.722657     3.567922     5.076117   \n",
       "lyin        0.377359     3.881109     0.669349     5.147825     8.407166   \n",
       "sittin      0.421247     5.317361     0.866731     5.146924     5.604308   \n",
       "standin     0.374181     4.128552     0.721632     4.046885     4.785235   \n",
       "walkin      2.461158     3.151718     1.638863     3.354381     5.730645   \n",
       "\n",
       "         var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                        \n",
       "bending     0.564301     7.214285     0.921230    10.606611  \n",
       "cyclin      1.940822     3.894445     1.726250     3.652404  \n",
       "lyin        0.377567     3.892634     0.669174     5.159684  \n",
       "sittin      0.421387     5.354299     0.866980     5.193776  \n",
       "standin     0.374366     4.178717     0.721755     4.092250  \n",
       "walkin      2.466088     3.223939     1.643607     3.430036  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('ATYPE').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>bending</td>\n",
       "      <td>34.597288</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>17.382712</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>24.515593</td>\n",
       "      <td>34.597288</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>17.382712</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>24.515593</td>\n",
       "      <td>...</td>\n",
       "      <td>34.597288</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>17.382712</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>24.515593</td>\n",
       "      <td>34.597288</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>17.382712</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>24.515593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cyclin</td>\n",
       "      <td>37.204545</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>16.170455</td>\n",
       "      <td>2.871970</td>\n",
       "      <td>18.033939</td>\n",
       "      <td>37.204545</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>16.170455</td>\n",
       "      <td>2.871970</td>\n",
       "      <td>18.033939</td>\n",
       "      <td>...</td>\n",
       "      <td>37.204545</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>16.170455</td>\n",
       "      <td>2.871970</td>\n",
       "      <td>18.033939</td>\n",
       "      <td>37.204545</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>16.170455</td>\n",
       "      <td>2.871970</td>\n",
       "      <td>18.033939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lyin</td>\n",
       "      <td>40.491404</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>7.308246</td>\n",
       "      <td>0.604035</td>\n",
       "      <td>10.464912</td>\n",
       "      <td>40.491404</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>7.308246</td>\n",
       "      <td>0.604035</td>\n",
       "      <td>10.464912</td>\n",
       "      <td>...</td>\n",
       "      <td>40.491404</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>7.308246</td>\n",
       "      <td>0.604035</td>\n",
       "      <td>10.464912</td>\n",
       "      <td>40.491404</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>7.308246</td>\n",
       "      <td>0.604035</td>\n",
       "      <td>10.464912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sittin</td>\n",
       "      <td>42.306897</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>15.288448</td>\n",
       "      <td>0.866034</td>\n",
       "      <td>16.763276</td>\n",
       "      <td>42.306897</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>15.288448</td>\n",
       "      <td>0.866034</td>\n",
       "      <td>16.763276</td>\n",
       "      <td>...</td>\n",
       "      <td>41.531034</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>15.173448</td>\n",
       "      <td>0.830690</td>\n",
       "      <td>16.401207</td>\n",
       "      <td>41.531034</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>15.173448</td>\n",
       "      <td>0.830690</td>\n",
       "      <td>16.401207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>standin</td>\n",
       "      <td>44.255500</td>\n",
       "      <td>0.428167</td>\n",
       "      <td>14.437167</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>14.179500</td>\n",
       "      <td>44.255500</td>\n",
       "      <td>0.428167</td>\n",
       "      <td>14.437167</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>14.179500</td>\n",
       "      <td>...</td>\n",
       "      <td>44.255500</td>\n",
       "      <td>0.428167</td>\n",
       "      <td>14.437167</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>14.179500</td>\n",
       "      <td>44.255500</td>\n",
       "      <td>0.428167</td>\n",
       "      <td>14.437167</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>14.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>walkin</td>\n",
       "      <td>35.790400</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>15.501400</td>\n",
       "      <td>3.628400</td>\n",
       "      <td>16.913200</td>\n",
       "      <td>35.790400</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>15.501400</td>\n",
       "      <td>3.628400</td>\n",
       "      <td>16.913200</td>\n",
       "      <td>...</td>\n",
       "      <td>35.790400</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>15.501400</td>\n",
       "      <td>3.628400</td>\n",
       "      <td>16.913200</td>\n",
       "      <td>35.790400</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>15.501400</td>\n",
       "      <td>3.628400</td>\n",
       "      <td>16.913200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                         \n",
       "bending  34.597288   0.459831  17.382712   0.800169  24.515593    34.597288   \n",
       "cyclin   37.204545   2.430000  16.170455   2.871970  18.033939    37.204545   \n",
       "lyin     40.491404   0.392982   7.308246   0.604035  10.464912    40.491404   \n",
       "sittin   42.306897   0.370000  15.288448   0.866034  16.763276    42.306897   \n",
       "standin  44.255500   0.428167  14.437167   0.657500  14.179500    44.255500   \n",
       "walkin   35.790400   4.290000  15.501400   3.628400  16.913200    35.790400   \n",
       "\n",
       "         var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                        ...                \n",
       "bending     0.459831    17.382712     0.800169    24.515593  ...    34.597288   \n",
       "cyclin      2.430000    16.170455     2.871970    18.033939  ...    37.204545   \n",
       "lyin        0.392982     7.308246     0.604035    10.464912  ...    40.491404   \n",
       "sittin      0.370000    15.288448     0.866034    16.763276  ...    41.531034   \n",
       "standin     0.428167    14.437167     0.657500    14.179500  ...    44.255500   \n",
       "walkin      4.290000    15.501400     3.628400    16.913200  ...    35.790400   \n",
       "\n",
       "         var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                      \n",
       "bending     0.459831    17.382712     0.800169    24.515593    34.597288   \n",
       "cyclin      2.430000    16.170455     2.871970    18.033939    37.204545   \n",
       "lyin        0.392982     7.308246     0.604035    10.464912    40.491404   \n",
       "sittin      0.370000    15.173448     0.830690    16.401207    41.531034   \n",
       "standin     0.428167    14.437167     0.657500    14.179500    44.255500   \n",
       "walkin      4.290000    15.501400     3.628400    16.913200    35.790400   \n",
       "\n",
       "         var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                        \n",
       "bending     0.459831    17.382712     0.800169    24.515593  \n",
       "cyclin      2.430000    16.170455     2.871970    18.033939  \n",
       "lyin        0.392982     7.308246     0.604035    10.464912  \n",
       "sittin      0.370000    15.173448     0.830690    16.401207  \n",
       "standin     0.428167    14.437167     0.657500    14.179500  \n",
       "walkin      4.290000    15.501400     3.628400    16.913200  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('ATYPE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>bending</td>\n",
       "      <td>11.936775</td>\n",
       "      <td>0.423379</td>\n",
       "      <td>6.681963</td>\n",
       "      <td>0.814495</td>\n",
       "      <td>9.677460</td>\n",
       "      <td>11.936775</td>\n",
       "      <td>0.423379</td>\n",
       "      <td>6.681963</td>\n",
       "      <td>0.814495</td>\n",
       "      <td>9.677460</td>\n",
       "      <td>...</td>\n",
       "      <td>11.936775</td>\n",
       "      <td>0.423379</td>\n",
       "      <td>6.681963</td>\n",
       "      <td>0.814495</td>\n",
       "      <td>9.677460</td>\n",
       "      <td>11.936775</td>\n",
       "      <td>0.423379</td>\n",
       "      <td>6.681963</td>\n",
       "      <td>0.814495</td>\n",
       "      <td>9.677460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cyclin</td>\n",
       "      <td>3.936100</td>\n",
       "      <td>1.907624</td>\n",
       "      <td>3.280253</td>\n",
       "      <td>1.487486</td>\n",
       "      <td>3.265736</td>\n",
       "      <td>3.936100</td>\n",
       "      <td>1.907624</td>\n",
       "      <td>3.280253</td>\n",
       "      <td>1.487486</td>\n",
       "      <td>3.265736</td>\n",
       "      <td>...</td>\n",
       "      <td>3.936100</td>\n",
       "      <td>1.907624</td>\n",
       "      <td>3.280253</td>\n",
       "      <td>1.487486</td>\n",
       "      <td>3.265736</td>\n",
       "      <td>3.936100</td>\n",
       "      <td>1.907624</td>\n",
       "      <td>3.280253</td>\n",
       "      <td>1.487486</td>\n",
       "      <td>3.265736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lyin</td>\n",
       "      <td>5.823699</td>\n",
       "      <td>0.243787</td>\n",
       "      <td>3.837303</td>\n",
       "      <td>0.636870</td>\n",
       "      <td>4.170597</td>\n",
       "      <td>5.823699</td>\n",
       "      <td>0.243787</td>\n",
       "      <td>3.837303</td>\n",
       "      <td>0.636870</td>\n",
       "      <td>4.170597</td>\n",
       "      <td>...</td>\n",
       "      <td>5.823699</td>\n",
       "      <td>0.243787</td>\n",
       "      <td>3.837303</td>\n",
       "      <td>0.636870</td>\n",
       "      <td>4.170597</td>\n",
       "      <td>5.823699</td>\n",
       "      <td>0.243787</td>\n",
       "      <td>3.837303</td>\n",
       "      <td>0.636870</td>\n",
       "      <td>4.170597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sittin</td>\n",
       "      <td>3.615483</td>\n",
       "      <td>0.345055</td>\n",
       "      <td>5.476327</td>\n",
       "      <td>0.897030</td>\n",
       "      <td>5.231980</td>\n",
       "      <td>3.615483</td>\n",
       "      <td>0.345055</td>\n",
       "      <td>5.476327</td>\n",
       "      <td>0.897030</td>\n",
       "      <td>5.231980</td>\n",
       "      <td>...</td>\n",
       "      <td>6.613111</td>\n",
       "      <td>0.345055</td>\n",
       "      <td>5.724878</td>\n",
       "      <td>0.889920</td>\n",
       "      <td>5.644047</td>\n",
       "      <td>6.613111</td>\n",
       "      <td>0.345055</td>\n",
       "      <td>5.724878</td>\n",
       "      <td>0.889920</td>\n",
       "      <td>5.644047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>standin</td>\n",
       "      <td>2.255689</td>\n",
       "      <td>0.629720</td>\n",
       "      <td>4.169106</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>4.009013</td>\n",
       "      <td>2.255689</td>\n",
       "      <td>0.629720</td>\n",
       "      <td>4.169106</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>4.009013</td>\n",
       "      <td>...</td>\n",
       "      <td>2.255689</td>\n",
       "      <td>0.629720</td>\n",
       "      <td>4.169106</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>4.009013</td>\n",
       "      <td>2.255689</td>\n",
       "      <td>0.629720</td>\n",
       "      <td>4.169106</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>4.009013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>walkin</td>\n",
       "      <td>4.045297</td>\n",
       "      <td>2.379193</td>\n",
       "      <td>2.376477</td>\n",
       "      <td>1.605666</td>\n",
       "      <td>2.512573</td>\n",
       "      <td>4.045297</td>\n",
       "      <td>2.379193</td>\n",
       "      <td>2.376477</td>\n",
       "      <td>1.605666</td>\n",
       "      <td>2.512573</td>\n",
       "      <td>...</td>\n",
       "      <td>4.045297</td>\n",
       "      <td>2.379193</td>\n",
       "      <td>2.376477</td>\n",
       "      <td>1.605666</td>\n",
       "      <td>2.512573</td>\n",
       "      <td>4.045297</td>\n",
       "      <td>2.379193</td>\n",
       "      <td>2.376477</td>\n",
       "      <td>1.605666</td>\n",
       "      <td>2.512573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                         \n",
       "bending  11.936775   0.423379   6.681963   0.814495   9.677460    11.936775   \n",
       "cyclin    3.936100   1.907624   3.280253   1.487486   3.265736     3.936100   \n",
       "lyin      5.823699   0.243787   3.837303   0.636870   4.170597     5.823699   \n",
       "sittin    3.615483   0.345055   5.476327   0.897030   5.231980     3.615483   \n",
       "standin   2.255689   0.629720   4.169106   0.854719   4.009013     2.255689   \n",
       "walkin    4.045297   2.379193   2.376477   1.605666   2.512573     4.045297   \n",
       "\n",
       "         var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                        ...                \n",
       "bending     0.423379     6.681963     0.814495     9.677460  ...    11.936775   \n",
       "cyclin      1.907624     3.280253     1.487486     3.265736  ...     3.936100   \n",
       "lyin        0.243787     3.837303     0.636870     4.170597  ...     5.823699   \n",
       "sittin      0.345055     5.476327     0.897030     5.231980  ...     6.613111   \n",
       "standin     0.629720     4.169106     0.854719     4.009013  ...     2.255689   \n",
       "walkin      2.379193     2.376477     1.605666     2.512573  ...     4.045297   \n",
       "\n",
       "         var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                      \n",
       "bending     0.423379     6.681963     0.814495     9.677460    11.936775   \n",
       "cyclin      1.907624     3.280253     1.487486     3.265736     3.936100   \n",
       "lyin        0.243787     3.837303     0.636870     4.170597     5.823699   \n",
       "sittin      0.345055     5.724878     0.889920     5.644047     6.613111   \n",
       "standin     0.629720     4.169106     0.854719     4.009013     2.255689   \n",
       "walkin      2.379193     2.376477     1.605666     2.512573     4.045297   \n",
       "\n",
       "         var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                        \n",
       "bending     0.423379     6.681963     0.814495     9.677460  \n",
       "cyclin      1.907624     3.280253     1.487486     3.265736  \n",
       "lyin        0.243787     3.837303     0.636870     4.170597  \n",
       "sittin      0.345055     5.724878     0.889920     5.644047  \n",
       "standin     0.629720     4.169106     0.854719     4.009013  \n",
       "walkin      2.379193     2.376477     1.605666     2.512573  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('ATYPE').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizamos los datos a mean= 0 y std = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = dict()\n",
    "decoder = dict()\n",
    "counter = 0\n",
    "\n",
    "for itera in train_df['ATYPE'].unique():\n",
    "    encoder[itera] = counter\n",
    "    decoder[counter] = itera\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ATYPE'] = train_df['ATYPE'].apply(lambda x: encoder[x])\n",
    "test_df['ATYPE'] = test_df['ATYPE'].apply(lambda x: encoder[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "41883    5\n",
       "41884    5\n",
       "41885    5\n",
       "41886    5\n",
       "41887    5\n",
       "Name: ATYPE, Length: 41888, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['ATYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns.remove('ATYPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=False, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = sc(copy=False)\n",
    "scaler.fit(train_df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[columns] = scaler.transform(train_df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[columns] = scaler.transform(test_df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.575895</td>\n",
       "      <td>-0.500222</td>\n",
       "      <td>0.459846</td>\n",
       "      <td>-0.463988</td>\n",
       "      <td>1.106898</td>\n",
       "      <td>-0.575895</td>\n",
       "      <td>-0.500222</td>\n",
       "      <td>0.459846</td>\n",
       "      <td>-0.463988</td>\n",
       "      <td>1.106898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.532057</td>\n",
       "      <td>-0.497881</td>\n",
       "      <td>0.450926</td>\n",
       "      <td>-0.461891</td>\n",
       "      <td>1.086105</td>\n",
       "      <td>-0.519429</td>\n",
       "      <td>-0.497130</td>\n",
       "      <td>0.447944</td>\n",
       "      <td>-0.461080</td>\n",
       "      <td>1.079195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.243751</td>\n",
       "      <td>0.601693</td>\n",
       "      <td>0.395822</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>-0.243751</td>\n",
       "      <td>0.601693</td>\n",
       "      <td>0.395822</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224814</td>\n",
       "      <td>0.597723</td>\n",
       "      <td>0.385914</td>\n",
       "      <td>0.904619</td>\n",
       "      <td>0.221410</td>\n",
       "      <td>-0.219566</td>\n",
       "      <td>0.597236</td>\n",
       "      <td>0.382540</td>\n",
       "      <td>0.902363</td>\n",
       "      <td>0.220416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.169412</td>\n",
       "      <td>-0.543286</td>\n",
       "      <td>-1.236753</td>\n",
       "      <td>-0.556808</td>\n",
       "      <td>-0.946862</td>\n",
       "      <td>0.169412</td>\n",
       "      <td>-0.543286</td>\n",
       "      <td>-1.236753</td>\n",
       "      <td>-0.556808</td>\n",
       "      <td>-0.946862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156550</td>\n",
       "      <td>-0.540397</td>\n",
       "      <td>-1.208972</td>\n",
       "      <td>-0.552378</td>\n",
       "      <td>-0.930425</td>\n",
       "      <td>0.152806</td>\n",
       "      <td>-0.539667</td>\n",
       "      <td>-1.199911</td>\n",
       "      <td>-0.551124</td>\n",
       "      <td>-0.924980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.422323</td>\n",
       "      <td>-0.514642</td>\n",
       "      <td>0.121054</td>\n",
       "      <td>-0.453917</td>\n",
       "      <td>0.039654</td>\n",
       "      <td>0.422323</td>\n",
       "      <td>-0.514642</td>\n",
       "      <td>0.121054</td>\n",
       "      <td>-0.453917</td>\n",
       "      <td>0.039654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390691</td>\n",
       "      <td>-0.512100</td>\n",
       "      <td>0.118262</td>\n",
       "      <td>-0.452089</td>\n",
       "      <td>0.040568</td>\n",
       "      <td>0.381303</td>\n",
       "      <td>-0.511316</td>\n",
       "      <td>0.117253</td>\n",
       "      <td>-0.451024</td>\n",
       "      <td>0.040595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.703439</td>\n",
       "      <td>-0.516291</td>\n",
       "      <td>0.106054</td>\n",
       "      <td>-0.535483</td>\n",
       "      <td>-0.305308</td>\n",
       "      <td>0.703439</td>\n",
       "      <td>-0.516291</td>\n",
       "      <td>0.106054</td>\n",
       "      <td>-0.535483</td>\n",
       "      <td>-0.305308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648820</td>\n",
       "      <td>-0.513792</td>\n",
       "      <td>0.104068</td>\n",
       "      <td>-0.532405</td>\n",
       "      <td>-0.299610</td>\n",
       "      <td>0.633094</td>\n",
       "      <td>-0.513068</td>\n",
       "      <td>0.103046</td>\n",
       "      <td>-0.531493</td>\n",
       "      <td>-0.297825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.552607</td>\n",
       "      <td>1.404641</td>\n",
       "      <td>0.216370</td>\n",
       "      <td>1.037814</td>\n",
       "      <td>0.028578</td>\n",
       "      <td>-0.552607</td>\n",
       "      <td>1.404641</td>\n",
       "      <td>0.216370</td>\n",
       "      <td>1.037814</td>\n",
       "      <td>0.028578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510400</td>\n",
       "      <td>1.398655</td>\n",
       "      <td>0.210980</td>\n",
       "      <td>1.032044</td>\n",
       "      <td>0.028466</td>\n",
       "      <td>-0.497730</td>\n",
       "      <td>1.396258</td>\n",
       "      <td>0.209901</td>\n",
       "      <td>1.030366</td>\n",
       "      <td>0.028182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                       \n",
       "0      -0.575895  -0.500222   0.459846  -0.463988   1.106898    -0.575895   \n",
       "1      -0.243751   0.601693   0.395822   0.910000   0.226360    -0.243751   \n",
       "2       0.169412  -0.543286  -1.236753  -0.556808  -0.946862     0.169412   \n",
       "3       0.422323  -0.514642   0.121054  -0.453917   0.039654     0.422323   \n",
       "4       0.703439  -0.516291   0.106054  -0.535483  -0.305308     0.703439   \n",
       "5      -0.552607   1.404641   0.216370   1.037814   0.028578    -0.552607   \n",
       "\n",
       "       var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                      ...                \n",
       "0        -0.500222     0.459846    -0.463988     1.106898  ...    -0.532057   \n",
       "1         0.601693     0.395822     0.910000     0.226360  ...    -0.224814   \n",
       "2        -0.543286    -1.236753    -0.556808    -0.946862  ...     0.156550   \n",
       "3        -0.514642     0.121054    -0.453917     0.039654  ...     0.390691   \n",
       "4        -0.516291     0.106054    -0.535483    -0.305308  ...     0.648820   \n",
       "5         1.404641     0.216370     1.037814     0.028578  ...    -0.510400   \n",
       "\n",
       "       var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                    \n",
       "0        -0.497881     0.450926    -0.461891     1.086105    -0.519429   \n",
       "1         0.597723     0.385914     0.904619     0.221410    -0.219566   \n",
       "2        -0.540397    -1.208972    -0.552378    -0.930425     0.152806   \n",
       "3        -0.512100     0.118262    -0.452089     0.040568     0.381303   \n",
       "4        -0.513792     0.104068    -0.532405    -0.299610     0.633094   \n",
       "5         1.398655     0.210980     1.032044     0.028466    -0.497730   \n",
       "\n",
       "       var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                      \n",
       "0        -0.497130     0.447944    -0.461080     1.079195  \n",
       "1         0.597236     0.382540     0.902363     0.220416  \n",
       "2        -0.539667    -1.199911    -0.551124    -0.924980  \n",
       "3        -0.511316     0.117253    -0.451024     0.040595  \n",
       "4        -0.513068     0.103046    -0.531493    -0.297825  \n",
       "5         1.396258     0.209901     1.030366     0.028182  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('ATYPE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.529551</td>\n",
       "      <td>-0.486287</td>\n",
       "      <td>0.571889</td>\n",
       "      <td>-0.423256</td>\n",
       "      <td>1.252751</td>\n",
       "      <td>-0.529551</td>\n",
       "      <td>-0.486287</td>\n",
       "      <td>0.571889</td>\n",
       "      <td>-0.423256</td>\n",
       "      <td>1.252751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.461954</td>\n",
       "      <td>-0.482509</td>\n",
       "      <td>0.578201</td>\n",
       "      <td>-0.417655</td>\n",
       "      <td>1.250194</td>\n",
       "      <td>-0.442113</td>\n",
       "      <td>-0.481404</td>\n",
       "      <td>0.580228</td>\n",
       "      <td>-0.415937</td>\n",
       "      <td>1.249471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.182287</td>\n",
       "      <td>0.474402</td>\n",
       "      <td>0.355196</td>\n",
       "      <td>0.837767</td>\n",
       "      <td>0.318903</td>\n",
       "      <td>-0.182287</td>\n",
       "      <td>0.474402</td>\n",
       "      <td>0.355196</td>\n",
       "      <td>0.837767</td>\n",
       "      <td>0.318903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139404</td>\n",
       "      <td>0.479702</td>\n",
       "      <td>0.364958</td>\n",
       "      <td>0.843584</td>\n",
       "      <td>0.328774</td>\n",
       "      <td>-0.126634</td>\n",
       "      <td>0.481326</td>\n",
       "      <td>0.368115</td>\n",
       "      <td>0.845533</td>\n",
       "      <td>0.332087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>-0.518883</td>\n",
       "      <td>-1.228939</td>\n",
       "      <td>-0.542635</td>\n",
       "      <td>-0.771608</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>-0.518883</td>\n",
       "      <td>-1.228939</td>\n",
       "      <td>-0.542635</td>\n",
       "      <td>-0.771608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267221</td>\n",
       "      <td>-0.515156</td>\n",
       "      <td>-1.193952</td>\n",
       "      <td>-0.537055</td>\n",
       "      <td>-0.747225</td>\n",
       "      <td>0.271078</td>\n",
       "      <td>-0.514069</td>\n",
       "      <td>-1.182539</td>\n",
       "      <td>-0.535359</td>\n",
       "      <td>-0.739198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.497303</td>\n",
       "      <td>-0.530090</td>\n",
       "      <td>0.197536</td>\n",
       "      <td>-0.383166</td>\n",
       "      <td>0.135832</td>\n",
       "      <td>0.497303</td>\n",
       "      <td>-0.530090</td>\n",
       "      <td>0.197536</td>\n",
       "      <td>-0.383166</td>\n",
       "      <td>0.135832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395836</td>\n",
       "      <td>-0.526381</td>\n",
       "      <td>0.189579</td>\n",
       "      <td>-0.399076</td>\n",
       "      <td>0.096668</td>\n",
       "      <td>0.396874</td>\n",
       "      <td>-0.525300</td>\n",
       "      <td>0.193665</td>\n",
       "      <td>-0.397354</td>\n",
       "      <td>0.100998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.756840</td>\n",
       "      <td>-0.501727</td>\n",
       "      <td>0.045368</td>\n",
       "      <td>-0.510093</td>\n",
       "      <td>-0.236427</td>\n",
       "      <td>0.756840</td>\n",
       "      <td>-0.501727</td>\n",
       "      <td>0.045368</td>\n",
       "      <td>-0.510093</td>\n",
       "      <td>-0.236427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>-0.497973</td>\n",
       "      <td>0.060064</td>\n",
       "      <td>-0.504508</td>\n",
       "      <td>-0.219166</td>\n",
       "      <td>0.726535</td>\n",
       "      <td>-0.496877</td>\n",
       "      <td>0.064835</td>\n",
       "      <td>-0.502805</td>\n",
       "      <td>-0.213452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.370639</td>\n",
       "      <td>1.381370</td>\n",
       "      <td>0.235601</td>\n",
       "      <td>1.298176</td>\n",
       "      <td>0.157432</td>\n",
       "      <td>-0.370639</td>\n",
       "      <td>1.381370</td>\n",
       "      <td>0.235601</td>\n",
       "      <td>1.298176</td>\n",
       "      <td>0.157432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314352</td>\n",
       "      <td>1.388107</td>\n",
       "      <td>0.247268</td>\n",
       "      <td>1.304072</td>\n",
       "      <td>0.169452</td>\n",
       "      <td>-0.297746</td>\n",
       "      <td>1.390222</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>1.306105</td>\n",
       "      <td>0.173463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                       \n",
       "0      -0.529551  -0.486287   0.571889  -0.423256   1.252751    -0.529551   \n",
       "1      -0.182287   0.474402   0.355196   0.837767   0.318903    -0.182287   \n",
       "2       0.255495  -0.518883  -1.228939  -0.542635  -0.771608     0.255495   \n",
       "3       0.497303  -0.530090   0.197536  -0.383166   0.135832     0.497303   \n",
       "4       0.756840  -0.501727   0.045368  -0.510093  -0.236427     0.756840   \n",
       "5      -0.370639   1.381370   0.235601   1.298176   0.157432    -0.370639   \n",
       "\n",
       "       var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                      ...                \n",
       "0        -0.486287     0.571889    -0.423256     1.252751  ...    -0.461954   \n",
       "1         0.474402     0.355196     0.837767     0.318903  ...    -0.139404   \n",
       "2        -0.518883    -1.228939    -0.542635    -0.771608  ...     0.267221   \n",
       "3        -0.530090     0.197536    -0.383166     0.135832  ...     0.395836   \n",
       "4        -0.501727     0.045368    -0.510093    -0.236427  ...     0.732886   \n",
       "5         1.381370     0.235601     1.298176     0.157432  ...    -0.314352   \n",
       "\n",
       "       var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                    \n",
       "0        -0.482509     0.578201    -0.417655     1.250194    -0.442113   \n",
       "1         0.479702     0.364958     0.843584     0.328774    -0.126634   \n",
       "2        -0.515156    -1.193952    -0.537055    -0.747225     0.271078   \n",
       "3        -0.526381     0.189579    -0.399076     0.096668     0.396874   \n",
       "4        -0.497973     0.060064    -0.504508    -0.219166     0.726535   \n",
       "5         1.388107     0.247268     1.304072     0.169452    -0.297746   \n",
       "\n",
       "       var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                      \n",
       "0        -0.481404     0.580228    -0.415937     1.249471  \n",
       "1         0.481326     0.368115     0.845533     0.332087  \n",
       "2        -0.514069    -1.182539    -0.535359    -0.739198  \n",
       "3        -0.525300     0.193665    -0.397354     0.100998  \n",
       "4        -0.496877     0.064835    -0.502805    -0.213452  \n",
       "5         1.390222     0.251048     1.306105     0.173463  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('ATYPE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df[columns].to_numpy()\n",
    "y_train = to_categorical(train_df['ATYPE'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_df[columns].to_numpy()\n",
    "y_test = to_categorical(test_df['ATYPE'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecemos las estructuras de almacenamiento e iteración de nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [32, 256]\n",
    "epochs = [25]\n",
    "perceptrons = [64, 256, 1024]\n",
    "dropout = [0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = {'conf': None, 'xaccuracy': None, 'yaccuracy': None, 'xloss' : None, 'yloss' : None, \n",
    "                'bepoch' : None, 'baccuracy': None, 'bloss': None}\n",
    "models_analysis = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos las clases Keras necesarias para la creacion de nuestra MLP básica y componemos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = len(train_df.columns)-1\n",
    "output_dimension = len(train_df['ATYPE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\Keras-Tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\Keras-Tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\Keras-Tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\Keras-Tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\Keras-Tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\Keras-Tensorflow-gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\Keras-Tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\Keras-Tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 13s 302us/step - loss: 0.7599 - acc: 0.67810s - loss: 0.764\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 9s 218us/step - loss: 0.6563 - acc: 0.7104\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 6s 132us/step - loss: 0.6304 - acc: 0.7217\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 10s 232us/step - loss: 0.6152 - acc: 0.7284\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 12s 297us/step - loss: 0.6027 - acc: 0.7351\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 7s 175us/step - loss: 0.5923 - acc: 0.7393\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 6s 145us/step - loss: 0.5845 - acc: 0.7431\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 6s 136us/step - loss: 0.5795 - acc: 0.7447\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 5s 111us/step - loss: 0.5742 - acc: 0.7478\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 5s 113us/step - loss: 0.5697 - acc: 0.7484\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 12s 291us/step - loss: 0.5627 - acc: 0.7524\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 10s 237us/step - loss: 0.5590 - acc: 0.75272s - - ETA: 1s - los\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 10s 240us/step - loss: 0.5572 - acc: 0.7550\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 11s 264us/step - loss: 0.5544 - acc: 0.7569\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 6s 143us/step - loss: 0.5512 - acc: 0.7581\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 7s 162us/step - loss: 0.5496 - acc: 0.7586\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 6s 142us/step - loss: 0.5494 - acc: 0.7600\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 8s 188us/step - loss: 0.5471 - acc: 0.7581\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 7s 170us/step - loss: 0.5446 - acc: 0.7604\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 10s 248us/step - loss: 0.5422 - acc: 0.7619\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 7s 175us/step - loss: 0.5412 - acc: 0.7638\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 6s 142us/step - loss: 0.5381 - acc: 0.7651\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 5s 130us/step - loss: 0.5373 - acc: 0.7616\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 6s 133us/step - loss: 0.5388 - acc: 0.7649\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 7s 157us/step - loss: 0.5362 - acc: 0.7652\n",
      "350/350 [==============================] - 0s 336us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 6s 138us/step - loss: 0.9483 - acc: 0.6249\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 3s 83us/step - loss: 0.7366 - acc: 0.6876\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 4s 86us/step - loss: 0.6945 - acc: 0.6979\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 6s 152us/step - loss: 0.6662 - acc: 0.7091\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 2s 52us/step - loss: 0.6488 - acc: 0.7142\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 2s 52us/step - loss: 0.6389 - acc: 0.7187\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 3s 62us/step - loss: 0.6275 - acc: 0.7241\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 3s 83us/step - loss: 0.6179 - acc: 0.7274\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 3s 69us/step - loss: 0.6122 - acc: 0.7315\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 3s 63us/step - loss: 0.6094 - acc: 0.7305\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 3s 62us/step - loss: 0.6016 - acc: 0.7362\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 2s 53us/step - loss: 0.5967 - acc: 0.7383\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 1s 29us/step - loss: 0.5931 - acc: 0.7388\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 1s 28us/step - loss: 0.5895 - acc: 0.7412\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5849 - acc: 0.7410\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 2s 41us/step - loss: 0.5820 - acc: 0.7428\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 1s 34us/step - loss: 0.5809 - acc: 0.7454\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 1s 25us/step - loss: 0.5770 - acc: 0.7469\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 1s 27us/step - loss: 0.5733 - acc: 0.7465\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5710 - acc: 0.7481\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5701 - acc: 0.7496\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5690 - acc: 0.7486\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 1s 25us/step - loss: 0.5657 - acc: 0.7529\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 1s 27us/step - loss: 0.5627 - acc: 0.7520\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 1s 28us/step - loss: 0.5606 - acc: 0.7540\n",
      "350/350 [==============================] - 0s 382us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 7s 160us/step - loss: 0.7267 - acc: 0.6893\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 5s 124us/step - loss: 0.6385 - acc: 0.7172\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 5s 117us/step - loss: 0.6100 - acc: 0.7310\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 11s 269us/step - loss: 0.5885 - acc: 0.7419\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 10s 247us/step - loss: 0.5761 - acc: 0.7485\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 7s 161us/step - loss: 0.5643 - acc: 0.7505\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 7s 171us/step - loss: 0.5560 - acc: 0.7549\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 8s 187us/step - loss: 0.5518 - acc: 0.7581\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 6s 148us/step - loss: 0.5468 - acc: 0.7594\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 11s 274us/step - loss: 0.5409 - acc: 0.7626\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41888/41888 [==============================] - 9s 224us/step - loss: 0.5388 - acc: 0.7634\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 10s 233us/step - loss: 0.5354 - acc: 0.7653\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 10s 243us/step - loss: 0.5304 - acc: 0.7686\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 7s 169us/step - loss: 0.5294 - acc: 0.7686\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 8s 198us/step - loss: 0.5278 - acc: 0.7694\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 8s 183us/step - loss: 0.5226 - acc: 0.7718\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 8s 185us/step - loss: 0.5206 - acc: 0.7734\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 11s 273us/step - loss: 0.5188 - acc: 0.7725\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 8s 202us/step - loss: 0.5172 - acc: 0.7729\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 5s 130us/step - loss: 0.5141 - acc: 0.7734\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 6s 152us/step - loss: 0.5130 - acc: 0.7740\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 6s 134us/step - loss: 0.5108 - acc: 0.7758\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 6s 155us/step - loss: 0.5112 - acc: 0.7754\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 7s 164us/step - loss: 0.5087 - acc: 0.7781 0s - loss: 0.5087\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 13s 309us/step - loss: 0.5057 - acc: 0.7785\n",
      "350/350 [==============================] - 0s 559us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 86us/step - loss: 0.8442 - acc: 0.6489\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 3s 75us/step - loss: 0.6986 - acc: 0.6999\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 3s 81us/step - loss: 0.6654 - acc: 0.7086\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 4s 93us/step - loss: 0.6430 - acc: 0.7156: 0s - loss: 0.6395 - \n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 3s 72us/step - loss: 0.6283 - acc: 0.7220\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.6140 - acc: 0.7312\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 3s 66us/step - loss: 0.6041 - acc: 0.7349: 2s\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 2s 40us/step - loss: 0.5956 - acc: 0.7379\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 2s 57us/step - loss: 0.5885 - acc: 0.7420\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 2s 44us/step - loss: 0.5812 - acc: 0.7449\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 2s 39us/step - loss: 0.5771 - acc: 0.7468\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 2s 43us/step - loss: 0.5711 - acc: 0.7485\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 2s 39us/step - loss: 0.5685 - acc: 0.7508\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 2s 42us/step - loss: 0.5656 - acc: 0.7531\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 2s 42us/step - loss: 0.5609 - acc: 0.7539\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 2s 40us/step - loss: 0.5582 - acc: 0.7538\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 2s 38us/step - loss: 0.5541 - acc: 0.7546\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 2s 59us/step - loss: 0.5511 - acc: 0.7567\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 1s 33us/step - loss: 0.5499 - acc: 0.7576\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 1s 33us/step - loss: 0.5462 - acc: 0.7599\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 1s 34us/step - loss: 0.5448 - acc: 0.7606\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 1s 32us/step - loss: 0.5420 - acc: 0.7626\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 1s 33us/step - loss: 0.5415 - acc: 0.7622\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 1s 34us/step - loss: 0.5398 - acc: 0.7634\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 1s 35us/step - loss: 0.5351 - acc: 0.7651\n",
      "350/350 [==============================] - 0s 470us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 16s 371us/step - loss: 0.7072 - acc: 0.6929\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 12s 287us/step - loss: 0.6186 - acc: 0.7264\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 10s 246us/step - loss: 0.5881 - acc: 0.7420\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 10s 236us/step - loss: 0.5696 - acc: 0.7510\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 17s 401us/step - loss: 0.5556 - acc: 0.7541\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 15s 348us/step - loss: 0.5485 - acc: 0.7564\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 14s 324us/step - loss: 0.5430 - acc: 0.7592\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 10s 236us/step - loss: 0.5366 - acc: 0.7625\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 9s 220us/step - loss: 0.5316 - acc: 0.7687\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 11s 271us/step - loss: 0.5262 - acc: 0.76855s - los\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 15s 355us/step - loss: 0.5240 - acc: 0.7705\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 12s 296us/step - loss: 0.5178 - acc: 0.7729\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 11s 251us/step - loss: 0.5139 - acc: 0.7749\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 10s 228us/step - loss: 0.5131 - acc: 0.7749\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 13s 316us/step - loss: 0.5106 - acc: 0.7758\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 16s 377us/step - loss: 0.5073 - acc: 0.7779\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 15s 348us/step - loss: 0.5057 - acc: 0.7790\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 9s 225us/step - loss: 0.5046 - acc: 0.7792\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 11s 252us/step - loss: 0.5018 - acc: 0.7823\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 12s 294us/step - loss: 0.4990 - acc: 0.7827\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 16s 385us/step - loss: 0.4960 - acc: 0.7826\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 10s 232us/step - loss: 0.4936 - acc: 0.7837\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 9s 216us/step - loss: 0.4930 - acc: 0.7849\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 8s 202us/step - loss: 0.4906 - acc: 0.7863\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 13s 320us/step - loss: 0.4898 - acc: 0.7850\n",
      "350/350 [==============================] - 0s 781us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 105us/step - loss: 0.7827 - acc: 0.6726\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 3s 80us/step - loss: 0.6657 - acc: 0.7092\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 5s 123us/step - loss: 0.6329 - acc: 0.7210\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 3s 70us/step - loss: 0.6174 - acc: 0.7303\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 3s 77us/step - loss: 0.5995 - acc: 0.7360\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 4s 94us/step - loss: 0.5872 - acc: 0.7441: 0s - loss: 0.5873 - acc: 0.\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 4s 98us/step - loss: 0.5754 - acc: 0.7472\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 3s 72us/step - loss: 0.5687 - acc: 0.7503\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 2s 58us/step - loss: 0.5609 - acc: 0.7528\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 2s 54us/step - loss: 0.5574 - acc: 0.7537: 1s - l\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 3s 75us/step - loss: 0.5501 - acc: 0.7574\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 2s 56us/step - loss: 0.5448 - acc: 0.7592\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 3s 60us/step - loss: 0.5409 - acc: 0.7619\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41888/41888 [==============================] - 2s 59us/step - loss: 0.5380 - acc: 0.7625: 0s - loss: 0.5377 - acc: 0.762\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 2s 55us/step - loss: 0.5339 - acc: 0.7647\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 2s 59us/step - loss: 0.5309 - acc: 0.7653\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 3s 73us/step - loss: 0.5312 - acc: 0.7640\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 2s 51us/step - loss: 0.5267 - acc: 0.7712\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 2s 50us/step - loss: 0.5239 - acc: 0.7706\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 3s 60us/step - loss: 0.5209 - acc: 0.7692\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 3s 62us/step - loss: 0.5188 - acc: 0.7728\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 3s 62us/step - loss: 0.5169 - acc: 0.7745\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 3s 78us/step - loss: 0.5159 - acc: 0.7726\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 3s 74us/step - loss: 0.5119 - acc: 0.7777\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 3s 67us/step - loss: 0.5115 - acc: 0.7759: 1s \n",
      "350/350 [==============================] - 0s 818us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 11s 268us/step - loss: 0.7264 - acc: 0.6860\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 8s 186us/step - loss: 0.6335 - acc: 0.7207\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 9s 217us/step - loss: 0.6058 - acc: 0.7351\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 14s 345us/step - loss: 0.5886 - acc: 0.7408\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 18s 420us/step - loss: 0.5746 - acc: 0.7490\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 17s 394us/step - loss: 0.5644 - acc: 0.7527\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 8s 180us/step - loss: 0.5562 - acc: 0.7549\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 9s 203us/step - loss: 0.5505 - acc: 0.7597\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 8s 185us/step - loss: 0.5458 - acc: 0.7606\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 14s 325us/step - loss: 0.5426 - acc: 0.7625\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 12s 284us/step - loss: 0.5373 - acc: 0.7676\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 9s 205us/step - loss: 0.5340 - acc: 0.7675\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 10s 234us/step - loss: 0.5340 - acc: 0.76470s - loss: 0.5333 - acc\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 12s 275us/step - loss: 0.5283 - acc: 0.7691\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 14s 333us/step - loss: 0.5280 - acc: 0.7683\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 12s 294us/step - loss: 0.5249 - acc: 0.77150s - loss: 0.5\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 15s 366us/step - loss: 0.5216 - acc: 0.7724\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 9s 205us/step - loss: 0.5230 - acc: 0.7700\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 8s 189us/step - loss: 0.5206 - acc: 0.7728\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 13s 304us/step - loss: 0.5158 - acc: 0.7733\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 17s 406us/step - loss: 0.5165 - acc: 0.7729\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 8s 186us/step - loss: 0.5133 - acc: 0.7764\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 7s 171us/step - loss: 0.5107 - acc: 0.7768\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 9s 214us/step - loss: 0.5106 - acc: 0.7772\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 18s 436us/step - loss: 0.5080 - acc: 0.7771\n",
      "350/350 [==============================] - 0s 910us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 90us/step - loss: 0.8318 - acc: 0.6537\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 3s 81us/step - loss: 0.6918 - acc: 0.6992\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 3s 81us/step - loss: 0.6530 - acc: 0.7157\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 3s 80us/step - loss: 0.6331 - acc: 0.7195\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 4s 93us/step - loss: 0.6219 - acc: 0.7256\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 4s 89us/step - loss: 0.6098 - acc: 0.7305\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 2s 48us/step - loss: 0.6008 - acc: 0.7366\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 2s 45us/step - loss: 0.5915 - acc: 0.7383\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 2s 57us/step - loss: 0.5847 - acc: 0.7425\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 2s 38us/step - loss: 0.5763 - acc: 0.7468\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 2s 37us/step - loss: 0.5716 - acc: 0.7484\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 2s 41us/step - loss: 0.5664 - acc: 0.7514\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 2s 39us/step - loss: 0.5592 - acc: 0.7546\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 4s 97us/step - loss: 0.5571 - acc: 0.7555\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 2s 44us/step - loss: 0.5544 - acc: 0.7548\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 3s 67us/step - loss: 0.5508 - acc: 0.7582\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 2s 46us/step - loss: 0.5489 - acc: 0.7580\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 2s 42us/step - loss: 0.5447 - acc: 0.7609\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 2s 44us/step - loss: 0.5420 - acc: 0.7608\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 2s 43us/step - loss: 0.5407 - acc: 0.7621\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 2s 43us/step - loss: 0.5406 - acc: 0.7634\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 2s 53us/step - loss: 0.5387 - acc: 0.7617\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 3s 80us/step - loss: 0.5358 - acc: 0.7636\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 4s 86us/step - loss: 0.5327 - acc: 0.7663\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 3s 62us/step - loss: 0.5316 - acc: 0.7660\n",
      "350/350 [==============================] - 0s 767us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 14s 335us/step - loss: 0.7056 - acc: 0.6936\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 9s 225us/step - loss: 0.6188 - acc: 0.7255\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 10s 243us/step - loss: 0.5864 - acc: 0.7385\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 14s 325us/step - loss: 0.5678 - acc: 0.7500\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 16s 391us/step - loss: 0.5562 - acc: 0.7542\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 17s 396us/step - loss: 0.5456 - acc: 0.7588\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 11s 269us/step - loss: 0.5413 - acc: 0.7633\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 11s 258us/step - loss: 0.5340 - acc: 0.7669\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 19s 456us/step - loss: 0.5280 - acc: 0.7681\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 14s 337us/step - loss: 0.5266 - acc: 0.7682\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 10s 250us/step - loss: 0.5226 - acc: 0.7716\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 11s 255us/step - loss: 0.5176 - acc: 0.7734\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 15s 362us/step - loss: 0.5155 - acc: 0.7741\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 12s 290us/step - loss: 0.5116 - acc: 0.7768\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 10s 230us/step - loss: 0.5098 - acc: 0.7772\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 15s 349us/step - loss: 0.5086 - acc: 0.7783\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41888/41888 [==============================] - 11s 263us/step - loss: 0.5042 - acc: 0.7804\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 8s 203us/step - loss: 0.5026 - acc: 0.7821\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 17s 411us/step - loss: 0.4989 - acc: 0.7808\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 10s 248us/step - loss: 0.4957 - acc: 0.7822\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 8s 190us/step - loss: 0.4959 - acc: 0.7829\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 9s 215us/step - loss: 0.4938 - acc: 0.7850\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 12s 275us/step - loss: 0.4915 - acc: 0.7853\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 14s 333us/step - loss: 0.4873 - acc: 0.7869\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 13s 313us/step - loss: 0.4858 - acc: 0.7894\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 95us/step - loss: 0.7879 - acc: 0.6655\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 3s 61us/step - loss: 0.6655 - acc: 0.7099\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 2s 50us/step - loss: 0.6280 - acc: 0.7253\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 2s 37us/step - loss: 0.6061 - acc: 0.7339\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 2s 38us/step - loss: 0.5889 - acc: 0.7410\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 2s 38us/step - loss: 0.5799 - acc: 0.7457\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 2s 37us/step - loss: 0.5672 - acc: 0.7515\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 2s 50us/step - loss: 0.5612 - acc: 0.7522\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 2s 45us/step - loss: 0.5531 - acc: 0.7562\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 2s 38us/step - loss: 0.5467 - acc: 0.7602\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 2s 38us/step - loss: 0.5456 - acc: 0.7597\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 2s 38us/step - loss: 0.5382 - acc: 0.7642\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 2s 39us/step - loss: 0.5358 - acc: 0.7652\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 2s 37us/step - loss: 0.5325 - acc: 0.7652\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 2s 39us/step - loss: 0.5289 - acc: 0.7664\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 2s 38us/step - loss: 0.5249 - acc: 0.7699\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 2s 39us/step - loss: 0.5230 - acc: 0.7705\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 3s 60us/step - loss: 0.5182 - acc: 0.7732\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 6s 146us/step - loss: 0.5173 - acc: 0.7742\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 4s 88us/step - loss: 0.5161 - acc: 0.7725\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 2s 56us/step - loss: 0.5150 - acc: 0.7723\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 3s 78us/step - loss: 0.5122 - acc: 0.7719: 1s - los\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 3s 61us/step - loss: 0.5104 - acc: 0.7747: 1s - loss: \n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 2s 59us/step - loss: 0.5087 - acc: 0.7776\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 2s 56us/step - loss: 0.5078 - acc: 0.7767\n",
      "350/350 [==============================] - 0s 994us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 16s 376us/step - loss: 0.6935 - acc: 0.6978\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 24s 573us/step - loss: 0.6030 - acc: 0.7337\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 22s 530us/step - loss: 0.5723 - acc: 0.7464\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 22s 524us/step - loss: 0.5592 - acc: 0.75321\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 17s 415us/step - loss: 0.5486 - acc: 0.75802s - lo - ETA: 0s - loss:\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 21s 492us/step - loss: 0.5393 - acc: 0.7625\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 19s 458us/step - loss: 0.5336 - acc: 0.7639\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 17s 397us/step - loss: 0.5265 - acc: 0.7684\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 20s 477us/step - loss: 0.5222 - acc: 0.77170s - loss: 0.5232 - acc:\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 21s 498us/step - loss: 0.5169 - acc: 0.77494s - loss: 0.5161 - acc: 0. - ETA: 3s - los\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 15s 360us/step - loss: 0.5137 - acc: 0.7772\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - ETA: 0s - loss: 0.5100 - acc: 0.777 - 17s 397us/step - loss: 0.5104 - acc: 0.7770\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 18s 421us/step - loss: 0.5048 - acc: 0.77911s - loss: 0.50\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 15s 364us/step - loss: 0.5030 - acc: 0.7818\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 22s 533us/step - loss: 0.4992 - acc: 0.7834\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 23s 543us/step - loss: 0.4969 - acc: 0.7832\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 15s 354us/step - loss: 0.4933 - acc: 0.7850\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 14s 332us/step - loss: 0.4912 - acc: 0.78600s - loss: 0.4909 - acc: 0.\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 22s 519us/step - loss: 0.4884 - acc: 0.7845\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 17s 409us/step - loss: 0.4869 - acc: 0.7874\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 18s 421us/step - loss: 0.4844 - acc: 0.7879\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 22s 515us/step - loss: 0.4817 - acc: 0.7907\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 24s 584us/step - loss: 0.4806 - acc: 0.7887\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 17s 398us/step - loss: 0.4791 - acc: 0.7912\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 21s 504us/step - loss: 0.4773 - acc: 0.7919\n",
      "350/350 [==============================] - 0s 995us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 107us/step - loss: 0.7475 - acc: 0.6835 \n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 4s 92us/step - loss: 0.6418 - acc: 0.7166\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 3s 76us/step - loss: 0.6103 - acc: 0.7301\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 3s 76us/step - loss: 0.5882 - acc: 0.7428\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5702 - acc: 0.7484\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 4s 84us/step - loss: 0.5595 - acc: 0.7537\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 4s 89us/step - loss: 0.5510 - acc: 0.7577\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 4s 93us/step - loss: 0.5432 - acc: 0.7625\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 4s 95us/step - loss: 0.5383 - acc: 0.7613\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 4s 98us/step - loss: 0.5299 - acc: 0.7664\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 4s 101us/step - loss: 0.5296 - acc: 0.7669\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 4s 95us/step - loss: 0.5236 - acc: 0.7710\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 4s 91us/step - loss: 0.5188 - acc: 0.7717\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 4s 101us/step - loss: 0.5157 - acc: 0.7734\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 4s 107us/step - loss: 0.5149 - acc: 0.7733\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 4s 106us/step - loss: 0.5100 - acc: 0.7772\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 4s 98us/step - loss: 0.5076 - acc: 0.7775\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41888/41888 [==============================] - 4s 101us/step - loss: 0.5055 - acc: 0.7781\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 3s 76us/step - loss: 0.5019 - acc: 0.7812\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 3s 76us/step - loss: 0.4995 - acc: 0.7808\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 3s 71us/step - loss: 0.4976 - acc: 0.7809\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 3s 72us/step - loss: 0.4938 - acc: 0.7840\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 3s 73us/step - loss: 0.4923 - acc: 0.7842\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 3s 70us/step - loss: 0.4902 - acc: 0.7859\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 3s 63us/step - loss: 0.4887 - acc: 0.7847\n",
      "350/350 [==============================] - 0s 946us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 12s 285us/step - loss: 0.7151 - acc: 0.6901\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 17s 415us/step - loss: 0.6295 - acc: 0.7213\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 9s 223us/step - loss: 0.5970 - acc: 0.7366\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 10s 244us/step - loss: 0.5784 - acc: 0.7462\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 11s 258us/step - loss: 0.5689 - acc: 0.7493\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 13s 321us/step - loss: 0.5604 - acc: 0.7526\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 13s 302us/step - loss: 0.5543 - acc: 0.7571\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 14s 334us/step - loss: 0.5478 - acc: 0.7571\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 11s 255us/step - loss: 0.5457 - acc: 0.7600\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 10s 236us/step - loss: 0.5409 - acc: 0.7620\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 11s 252us/step - loss: 0.5362 - acc: 0.7646\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 14s 332us/step - loss: 0.5350 - acc: 0.7657\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 14s 329us/step - loss: 0.5312 - acc: 0.7668\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 9s 210us/step - loss: 0.5311 - acc: 0.7679\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 10s 231us/step - loss: 0.5279 - acc: 0.7667\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 16s 383us/step - loss: 0.5272 - acc: 0.7685\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 16s 375us/step - loss: 0.5232 - acc: 0.7739\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 13s 306us/step - loss: 0.5201 - acc: 0.7707\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 9s 215us/step - loss: 0.5199 - acc: 0.7708\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 10s 234us/step - loss: 0.5168 - acc: 0.7730\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 11s 254us/step - loss: 0.5156 - acc: 0.7751\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 17s 406us/step - loss: 0.5131 - acc: 0.7768\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 14s 325us/step - loss: 0.5118 - acc: 0.77631s - loss: 0.5131 - acc: 0.77 - ETA: 1s - \n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 9s 224us/step - loss: 0.5094 - acc: 0.7770\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 13s 318us/step - loss: 0.5107 - acc: 0.7752\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 99us/step - loss: 0.7820 - acc: 0.6701\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 3s 80us/step - loss: 0.6611 - acc: 0.7115\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 3s 71us/step - loss: 0.6322 - acc: 0.7203\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 3s 64us/step - loss: 0.6121 - acc: 0.7306\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 3s 72us/step - loss: 0.5984 - acc: 0.7358\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 3s 68us/step - loss: 0.5884 - acc: 0.7412\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 3s 67us/step - loss: 0.5754 - acc: 0.7447\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 4s 87us/step - loss: 0.5700 - acc: 0.7475\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 3s 70us/step - loss: 0.5598 - acc: 0.7533\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 3s 65us/step - loss: 0.5537 - acc: 0.7569\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 3s 65us/step - loss: 0.5487 - acc: 0.7582\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 2s 60us/step - loss: 0.5437 - acc: 0.7599\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 2s 55us/step - loss: 0.5393 - acc: 0.7619\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 3s 68us/step - loss: 0.5406 - acc: 0.7624\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 2s 52us/step - loss: 0.5355 - acc: 0.7638\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 2s 54us/step - loss: 0.5316 - acc: 0.7687\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 2s 53us/step - loss: 0.5317 - acc: 0.7652\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 2s 54us/step - loss: 0.5255 - acc: 0.7696\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 2s 53us/step - loss: 0.5260 - acc: 0.7696\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 2s 60us/step - loss: 0.5222 - acc: 0.7698\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 3s 62us/step - loss: 0.5219 - acc: 0.7723\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 2s 55us/step - loss: 0.5184 - acc: 0.7735\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 2s 54us/step - loss: 0.5174 - acc: 0.7725\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 3s 67us/step - loss: 0.5149 - acc: 0.7736\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 3s 62us/step - loss: 0.5161 - acc: 0.7753\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 19s 449us/step - loss: 0.6968 - acc: 0.6960\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 14s 325us/step - loss: 0.6106 - acc: 0.7310\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 20s 469us/step - loss: 0.5804 - acc: 0.7434\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 17s 417us/step - loss: 0.5648 - acc: 0.7490\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 18s 422us/step - loss: 0.5533 - acc: 0.7561\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 14s 339us/step - loss: 0.5447 - acc: 0.7614\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 14s 346us/step - loss: 0.5377 - acc: 0.76350s - loss: 0.5378 - acc: 0.\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 18s 433us/step - loss: 0.5314 - acc: 0.76751s - loss:\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 15s 354us/step - loss: 0.5264 - acc: 0.7700\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 14s 345us/step - loss: 0.5232 - acc: 0.7724\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 18s 439us/step - loss: 0.5179 - acc: 0.7743\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 18s 422us/step - loss: 0.5164 - acc: 0.7745\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 19s 466us/step - loss: 0.5123 - acc: 0.7775\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 14s 346us/step - loss: 0.5083 - acc: 0.7805\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 19s 461us/step - loss: 0.5071 - acc: 0.77761s - \n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 15s 359us/step - loss: 0.5044 - acc: 0.7791\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 15s 350us/step - loss: 0.5006 - acc: 0.7808\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 19s 443us/step - loss: 0.4976 - acc: 0.7815\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 20s 487us/step - loss: 0.4967 - acc: 0.7834\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41888/41888 [==============================] - 17s 405us/step - loss: 0.4946 - acc: 0.7853\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 14s 337us/step - loss: 0.4938 - acc: 0.78321s - l\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 22s 526us/step - loss: 0.4903 - acc: 0.7878\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 16s 371us/step - loss: 0.4887 - acc: 0.7871\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 16s 388us/step - loss: 0.4871 - acc: 0.7895\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 18s 418us/step - loss: 0.4854 - acc: 0.78740s - loss: 0.4858 - acc: 0\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 5s 109us/step - loss: 0.7454 - acc: 0.6812 1s - loss: 0.771\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.6403 - acc: 0.7177\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 5s 111us/step - loss: 0.6055 - acc: 0.7334 2s - loss: 0.6130 - acc: 0 - ETA: 2s\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 4s 99us/step - loss: 0.5856 - acc: 0.7441: 0s - loss: 0.5869 - acc: 0\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 4s 92us/step - loss: 0.5718 - acc: 0.7473\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 4s 90us/step - loss: 0.5647 - acc: 0.7498\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 4s 100us/step - loss: 0.5541 - acc: 0.7561\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 3s 69us/step - loss: 0.5425 - acc: 0.7597\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 3s 72us/step - loss: 0.5373 - acc: 0.7631: 2s - loss: 0.5385 - acc:  - ET\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 3s 71us/step - loss: 0.5328 - acc: 0.7643\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 3s 69us/step - loss: 0.5298 - acc: 0.7648\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 4s 86us/step - loss: 0.5244 - acc: 0.7696\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 3s 71us/step - loss: 0.5191 - acc: 0.7729\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 3s 80us/step - loss: 0.5170 - acc: 0.7731\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 4s 84us/step - loss: 0.5143 - acc: 0.7724\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 4s 103us/step - loss: 0.5138 - acc: 0.7757\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 4s 96us/step - loss: 0.5101 - acc: 0.7772\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 4s 95us/step - loss: 0.5053 - acc: 0.7800\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 4s 90us/step - loss: 0.5042 - acc: 0.7799\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 4s 100us/step - loss: 0.5009 - acc: 0.7811\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 3s 80us/step - loss: 0.5007 - acc: 0.7822: 0s - loss: 0.5007 - acc: 0.782\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 3s 74us/step - loss: 0.4993 - acc: 0.7821: 0s - loss: 0.4979 - acc: 0.\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 3s 78us/step - loss: 0.4976 - acc: 0.7819\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 3s 77us/step - loss: 0.4951 - acc: 0.7832\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 4s 87us/step - loss: 0.4917 - acc: 0.7867\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 33s 794us/step - loss: 0.6911 - acc: 0.69830s - loss: 0.69\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 38s 900us/step - loss: 0.6009 - acc: 0.7353\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 36s 852us/step - loss: 0.5714 - acc: 0.7473\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 35s 843us/step - loss: 0.5567 - acc: 0.7541\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 31s 730us/step - loss: 0.5479 - acc: 0.7575\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 31s 729us/step - loss: 0.5391 - acc: 0.7639 0s - loss: 0.5387 - acc\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 33s 784us/step - loss: 0.5331 - acc: 0.7667\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 34s 823us/step - loss: 0.5256 - acc: 0.7683\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 35s 830us/step - loss: 0.5210 - acc: 0.7722\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 31s 743us/step - loss: 0.5174 - acc: 0.7728\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 31s 741us/step - loss: 0.5156 - acc: 0.7740\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 36s 863us/step - loss: 0.5110 - acc: 0.7775\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 30s 708us/step - loss: 0.5076 - acc: 0.77850s - loss: 0.5077 \n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 33s 786us/step - loss: 0.5026 - acc: 0.7795\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 35s 838us/step - loss: 0.4996 - acc: 0.7812\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 34s 801us/step - loss: 0.4985 - acc: 0.78231s - los\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 29s 691us/step - loss: 0.4965 - acc: 0.7836\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 35s 846us/step - loss: 0.4926 - acc: 0.78632s -\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 39s 923us/step - loss: 0.4899 - acc: 0.7851\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 35s 825us/step - loss: 0.4884 - acc: 0.78551s - loss\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 32s 763us/step - loss: 0.4853 - acc: 0.7881\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - ETA: 0s - loss: 0.4835 - acc: 0.786 - 34s 811us/step - loss: 0.4837 - acc: 0.7862\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 37s 883us/step - loss: 0.4814 - acc: 0.7881\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 30s 714us/step - loss: 0.4811 - acc: 0.7900\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 33s 794us/step - loss: 0.4791 - acc: 0.7920\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - ETA: 0s - loss: 0.7336 - acc: 0.685 - 8s 190us/step - loss: 0.7337 - acc: 0.6849\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 8s 180us/step - loss: 0.6277 - acc: 0.7222\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 7s 179us/step - loss: 0.5921 - acc: 0.7395\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - ETA: 0s - loss: 0.5799 - acc: 0.746 - 7s 168us/step - loss: 0.5796 - acc: 0.7463\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 7s 168us/step - loss: 0.5597 - acc: 0.7531\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 9s 208us/step - loss: 0.5486 - acc: 0.7573\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 7s 174us/step - loss: 0.5409 - acc: 0.7621\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 8s 194us/step - loss: 0.5321 - acc: 0.7652\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 7s 170us/step - loss: 0.5286 - acc: 0.7670\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - ETA: 0s - loss: 0.5242 - acc: 0.769 - 7s 162us/step - loss: 0.5243 - acc: 0.7693\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 7s 160us/step - loss: 0.5168 - acc: 0.7751\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 8s 200us/step - loss: 0.5153 - acc: 0.7725\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 8s 200us/step - loss: 0.5095 - acc: 0.7776\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 8s 188us/step - loss: 0.5064 - acc: 0.7765 0s - loss: 0.5086 - \n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 6s 134us/step - loss: 0.5037 - acc: 0.7800\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 5s 129us/step - loss: 0.4999 - acc: 0.7807\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 6s 151us/step - loss: 0.4990 - acc: 0.7821\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 6s 152us/step - loss: 0.4968 - acc: 0.7850\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41888/41888 [==============================] - 7s 157us/step - loss: 0.4925 - acc: 0.7865\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 6s 150us/step - loss: 0.4880 - acc: 0.7877\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 6s 150us/step - loss: 0.4875 - acc: 0.7875\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 8s 199us/step - loss: 0.4838 - acc: 0.7883\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 10s 234us/step - loss: 0.4801 - acc: 0.7910\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 7s 157us/step - loss: 0.4805 - acc: 0.7898\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 6s 155us/step - loss: 0.4798 - acc: 0.7903\n",
      "350/350 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "for hl1 in perceptrons:\n",
    "    for hl2 in perceptrons:\n",
    "        for bs in batch_size:\n",
    "            for ep in epochs:\n",
    "                for dp in dropout:\n",
    "                    model = Sequential()\n",
    "                    model.add(Dense(hl1, input_shape=(input_dimension,)))\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(Dropout(dp))\n",
    "                    model.add(Dense(hl2))\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(Dropout(dp))\n",
    "                    model.add(Dense(output_dimension))\n",
    "                    model.add(Activation('softmax'))\n",
    "\n",
    "                    mr = model_result.copy()\n",
    "                    mr['conf'] = [hl1, hl2, bs, ep, dp]            \n",
    "\n",
    "                    # loss function for one-hot vector\n",
    "                    # use of adam optimizer\n",
    "                    # accuracy is a good metric for classification tasks\n",
    "                    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "                    # train the network\n",
    "                    model_history = model.fit(x=x_train, y=y_train, batch_size=bs, epochs=ep)\n",
    "                    index_acc = argmax(model_history.history['acc'])\n",
    "                    mr['bloss'] = model_history.history['loss'][-1]\n",
    "                    mr['baccuracy'] = model_history.history['acc'][-1]\n",
    "                    mr['bepoch']= index_acc + 1\n",
    "                    mr['xloss'] = model_history.history['loss'][index_acc]\n",
    "                    mr['xaccuracy'] = model_history.history['acc'][index_acc]\n",
    "\n",
    "                    # Evaluate the network                                                             \n",
    "                    mr['yloss'], mr['yaccuracy'] = model.evaluate(x_test,y_test, batch_size=bs)\n",
    "                    models_analysis.append(mr)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP best network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conf': [1024, 1024, 32, 25, 0.05], 'xaccuracy': 0.7920406799083269, 'yaccuracy': 0.8028571442195347, 'xloss': 0.4790971497026812, 'yloss': 0.4716323331424168, 'bepoch': 25, 'baccuracy': 0.7920406799083269, 'bloss': 0.4790971497026812}\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "\n",
    "for itera in models_analysis:\n",
    "    if best_model is None:\n",
    "        best_model = itera\n",
    "    elif itera['baccuracy'] > best_model['baccuracy']:\n",
    "        best_model = itera\n",
    "\n",
    "print (best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing code MLP (sequential APi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 35s 831us/step - loss: 0.6963 - acc: 0.6939\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 21s 507us/step - loss: 0.6005 - acc: 0.7350\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 27s 642us/step - loss: 0.5747 - acc: 0.7466\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 21s 511us/step - loss: 0.5595 - acc: 0.7513\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 26s 615us/step - loss: 0.5485 - acc: 0.7567\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 31s 734us/step - loss: 0.5407 - acc: 0.7614\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 23s 557us/step - loss: 0.5305 - acc: 0.7670\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 32s 766us/step - loss: 0.5267 - acc: 0.7683\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 25s 597us/step - loss: 0.5203 - acc: 0.77371s - loss: 0.\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 32s 767us/step - loss: 0.5165 - acc: 0.7756\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 24s 582us/step - loss: 0.5116 - acc: 0.7760\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 38s 916us/step - loss: 0.5080 - acc: 0.7772\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 31s 730us/step - loss: 0.5063 - acc: 0.7798\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 34s 813us/step - loss: 0.5022 - acc: 0.78157s -  - ETA: 6s - loss - ET\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 37s 879us/step - loss: 0.4978 - acc: 0.7843\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 32s 757us/step - loss: 0.4945 - acc: 0.7836\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 31s 747us/step - loss: 0.4955 - acc: 0.7833\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 35s 831us/step - loss: 0.4919 - acc: 0.7857\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 35s 833us/step - loss: 0.4900 - acc: 0.7835\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 20s 469us/step - loss: 0.4877 - acc: 0.78651s - loss: 0\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 32s 767us/step - loss: 0.4863 - acc: 0.7875\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 34s 801us/step - loss: 0.4815 - acc: 0.7900\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 35s 832us/step - loss: 0.4822 - acc: 0.7894\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 35s 845us/step - loss: 0.4790 - acc: 0.7909\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 35s 838us/step - loss: 0.4749 - acc: 0.7922\n",
      "350/350 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(best_model['conf'][0], input_shape=(input_dimension,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(best_model['conf'][4]))\n",
    "model.add(Dense(best_model['conf'][1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(best_model['conf'][4]))\n",
    "model.add(Dense(output_dimension))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# loss function for one-hot vector\n",
    "# use of adam optimizer\n",
    "# accuracy is a good metric for classification tasks\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train the network\n",
    "model_history = model.fit(x=x_train, y=y_train, batch_size=best_model['conf'][2], epochs=best_model['bepoch'])\n",
    "\n",
    "a,b = model.evaluate(x_test,y_test, batch_size=best_model['conf'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='./img/mlp-best-model-sAPI.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : Loss(0.47486138588558907) - Accuracy: (0.7921600458365164)\n"
     ]
    }
   ],
   "source": [
    "print ('Train : Loss(%s) - Accuracy: (%s)' %(model_history.history['loss'][-1],model_history.history['acc'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : Loss(0.4890320369175502) - Accuracy: (0.7942857156481061)\n"
     ]
    }
   ],
   "source": [
    "print ('Test : Loss(%s) - Accuracy: (%s)' %(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing code MLP (Functional API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 35s 840us/step - loss: 0.6929 - acc: 0.6935\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 30s 713us/step - loss: 0.6026 - acc: 0.7338\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 32s 775us/step - loss: 0.5738 - acc: 0.7478\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 23s 558us/step - loss: 0.5613 - acc: 0.7523\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 33s 795us/step - loss: 0.5489 - acc: 0.7600\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 25s 598us/step - loss: 0.5382 - acc: 0.7637\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 29s 687us/step - loss: 0.5327 - acc: 0.7658\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 23s 551us/step - loss: 0.5282 - acc: 0.76820s - loss: 0.5281 - acc: 0.768\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 29s 699us/step - loss: 0.5206 - acc: 0.7720\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 31s 746us/step - loss: 0.5184 - acc: 0.77241s - loss: 0.51\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 25s 607us/step - loss: 0.5129 - acc: 0.7769\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 28s 658us/step - loss: 0.5102 - acc: 0.7792\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 27s 635us/step - loss: 0.5074 - acc: 0.7775\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 33s 783us/step - loss: 0.5033 - acc: 0.7798\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 23s 552us/step - loss: 0.4995 - acc: 0.78161s - l\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 31s 746us/step - loss: 0.4965 - acc: 0.78491s - loss:\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 23s 556us/step - loss: 0.4944 - acc: 0.7846\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 33s 791us/step - loss: 0.4904 - acc: 0.7877\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 27s 653us/step - loss: 0.4892 - acc: 0.7872\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 30s 722us/step - loss: 0.4905 - acc: 0.7861\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 22s 525us/step - loss: 0.4864 - acc: 0.7868\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 33s 789us/step - loss: 0.4833 - acc: 0.7906\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 29s 693us/step - loss: 0.4831 - acc: 0.7876\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 28s 661us/step - loss: 0.4822 - acc: 0.7880\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 26s 623us/step - loss: 0.4787 - acc: 0.7926\n",
      "350/350 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "\n",
    "input_1 = Input(shape=(input_dimension,))\n",
    "x = input_1\n",
    "x = Dense(best_model['conf'][0])(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(best_model['conf'][4])(x)\n",
    "x = Dense(best_model['conf'][1])(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(best_model['conf'][4])(x)\n",
    "output = Dense(output_dimension, activation = 'softmax' )(x)\n",
    "model = Model([input_1], output)\n",
    "\n",
    "# loss function for one-hot vector\n",
    "# use of adam optimizer\n",
    "# accuracy is a good metric for classification tasks\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train the network\n",
    "model_history = model.fit(x=x_train, y=y_train, batch_size=best_model['conf'][2], epochs=best_model['bepoch'])\n",
    "\n",
    "a,b = model.evaluate(x_test,y_test, batch_size=best_model['conf'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='./img/mlp-best-model-fAPI.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : Loss(0.47873473711556563) - Accuracy: (0.7926136363636364)\n"
     ]
    }
   ],
   "source": [
    "print ('Train : Loss(%s) - Accuracy: (%s)' %(model_history.history['loss'][-1],model_history.history['acc'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : Loss(0.46824740512030466) - Accuracy: (0.8199999986376081)\n"
     ]
    }
   ],
   "source": [
    "print ('Test : Loss(%s) - Accuracy: (%s)' %(a,b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-tensorflow-gpu",
   "language": "python",
   "name": "keras-tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
