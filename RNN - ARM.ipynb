{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset ARM: Analisis comparativo de MLPs,CNNs y RNNs para datos basados en Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "## Checking tensorflow backend engine\n",
    "import tensorflow as tf\n",
    "message = tf.constant('Hello world!')\n",
    "session = tf.Session()\n",
    "session.run(message)\n",
    "import keras.backend as K\n",
    "print(K.epsilon())\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical, plot_model\n",
    "\n",
    "from numpy import argmax,reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pandas.read_csv(\"https://raw.githubusercontent.com/e2its/datasets/master/ARM-Metric-train-TS.csv\",encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pandas.read_csv(\"https://raw.githubusercontent.com/e2its/datasets/master/ARM-Metric-test-TS.csv\",encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bending</th>\n",
       "      <td>34.249340</td>\n",
       "      <td>0.431254</td>\n",
       "      <td>16.755905</td>\n",
       "      <td>0.733249</td>\n",
       "      <td>23.503262</td>\n",
       "      <td>34.249340</td>\n",
       "      <td>0.431254</td>\n",
       "      <td>16.755905</td>\n",
       "      <td>0.733249</td>\n",
       "      <td>23.503262</td>\n",
       "      <td>...</td>\n",
       "      <td>34.030624</td>\n",
       "      <td>0.428355</td>\n",
       "      <td>16.659172</td>\n",
       "      <td>0.727505</td>\n",
       "      <td>23.361322</td>\n",
       "      <td>33.958319</td>\n",
       "      <td>0.427648</td>\n",
       "      <td>16.626693</td>\n",
       "      <td>0.726028</td>\n",
       "      <td>23.312530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyclin</th>\n",
       "      <td>36.743073</td>\n",
       "      <td>2.691047</td>\n",
       "      <td>16.397729</td>\n",
       "      <td>2.990645</td>\n",
       "      <td>17.391611</td>\n",
       "      <td>36.743073</td>\n",
       "      <td>2.691047</td>\n",
       "      <td>16.397729</td>\n",
       "      <td>2.990645</td>\n",
       "      <td>17.391611</td>\n",
       "      <td>...</td>\n",
       "      <td>36.514153</td>\n",
       "      <td>2.671655</td>\n",
       "      <td>16.289588</td>\n",
       "      <td>2.972231</td>\n",
       "      <td>17.278699</td>\n",
       "      <td>36.436510</td>\n",
       "      <td>2.667201</td>\n",
       "      <td>16.252897</td>\n",
       "      <td>2.965306</td>\n",
       "      <td>17.244941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyin</th>\n",
       "      <td>39.845100</td>\n",
       "      <td>0.342937</td>\n",
       "      <td>7.264530</td>\n",
       "      <td>0.580750</td>\n",
       "      <td>9.248505</td>\n",
       "      <td>39.845100</td>\n",
       "      <td>0.342937</td>\n",
       "      <td>7.264530</td>\n",
       "      <td>0.580750</td>\n",
       "      <td>9.248505</td>\n",
       "      <td>...</td>\n",
       "      <td>39.596826</td>\n",
       "      <td>0.341302</td>\n",
       "      <td>7.222859</td>\n",
       "      <td>0.578865</td>\n",
       "      <td>9.176209</td>\n",
       "      <td>39.513958</td>\n",
       "      <td>0.340598</td>\n",
       "      <td>7.208963</td>\n",
       "      <td>0.578144</td>\n",
       "      <td>9.152296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sittin</th>\n",
       "      <td>41.743949</td>\n",
       "      <td>0.401680</td>\n",
       "      <td>14.860580</td>\n",
       "      <td>0.749794</td>\n",
       "      <td>16.095726</td>\n",
       "      <td>41.743949</td>\n",
       "      <td>0.401680</td>\n",
       "      <td>14.860580</td>\n",
       "      <td>0.749794</td>\n",
       "      <td>16.095726</td>\n",
       "      <td>...</td>\n",
       "      <td>41.489445</td>\n",
       "      <td>0.399241</td>\n",
       "      <td>14.768017</td>\n",
       "      <td>0.743606</td>\n",
       "      <td>16.006578</td>\n",
       "      <td>41.402354</td>\n",
       "      <td>0.398618</td>\n",
       "      <td>14.736741</td>\n",
       "      <td>0.742544</td>\n",
       "      <td>15.974439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standin</th>\n",
       "      <td>43.854565</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>14.776667</td>\n",
       "      <td>0.615786</td>\n",
       "      <td>13.701405</td>\n",
       "      <td>43.854565</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>14.776667</td>\n",
       "      <td>0.615786</td>\n",
       "      <td>13.701405</td>\n",
       "      <td>...</td>\n",
       "      <td>43.575974</td>\n",
       "      <td>0.395777</td>\n",
       "      <td>14.687328</td>\n",
       "      <td>0.611673</td>\n",
       "      <td>13.613623</td>\n",
       "      <td>43.483259</td>\n",
       "      <td>0.395032</td>\n",
       "      <td>14.655550</td>\n",
       "      <td>0.610384</td>\n",
       "      <td>13.583375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walkin</th>\n",
       "      <td>34.424189</td>\n",
       "      <td>4.337724</td>\n",
       "      <td>15.393813</td>\n",
       "      <td>3.200638</td>\n",
       "      <td>16.018848</td>\n",
       "      <td>34.424189</td>\n",
       "      <td>4.337724</td>\n",
       "      <td>15.393813</td>\n",
       "      <td>3.200638</td>\n",
       "      <td>16.018848</td>\n",
       "      <td>...</td>\n",
       "      <td>34.205685</td>\n",
       "      <td>4.311599</td>\n",
       "      <td>15.295110</td>\n",
       "      <td>3.181547</td>\n",
       "      <td>15.921445</td>\n",
       "      <td>34.137645</td>\n",
       "      <td>4.302352</td>\n",
       "      <td>15.266241</td>\n",
       "      <td>3.175534</td>\n",
       "      <td>15.886737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                         \n",
       "bending  34.249340   0.431254  16.755905   0.733249  23.503262    34.249340   \n",
       "cyclin   36.743073   2.691047  16.397729   2.990645  17.391611    36.743073   \n",
       "lyin     39.845100   0.342937   7.264530   0.580750   9.248505    39.845100   \n",
       "sittin   41.743949   0.401680  14.860580   0.749794  16.095726    41.743949   \n",
       "standin  43.854565   0.398300  14.776667   0.615786  13.701405    43.854565   \n",
       "walkin   34.424189   4.337724  15.393813   3.200638  16.018848    34.424189   \n",
       "\n",
       "         var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                        ...                \n",
       "bending     0.431254    16.755905     0.733249    23.503262  ...    34.030624   \n",
       "cyclin      2.691047    16.397729     2.990645    17.391611  ...    36.514153   \n",
       "lyin        0.342937     7.264530     0.580750     9.248505  ...    39.596826   \n",
       "sittin      0.401680    14.860580     0.749794    16.095726  ...    41.489445   \n",
       "standin     0.398300    14.776667     0.615786    13.701405  ...    43.575974   \n",
       "walkin      4.337724    15.393813     3.200638    16.018848  ...    34.205685   \n",
       "\n",
       "         var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                      \n",
       "bending     0.428355    16.659172     0.727505    23.361322    33.958319   \n",
       "cyclin      2.671655    16.289588     2.972231    17.278699    36.436510   \n",
       "lyin        0.341302     7.222859     0.578865     9.176209    39.513958   \n",
       "sittin      0.399241    14.768017     0.743606    16.006578    41.402354   \n",
       "standin     0.395777    14.687328     0.611673    13.613623    43.483259   \n",
       "walkin      4.311599    15.295110     3.181547    15.921445    34.137645   \n",
       "\n",
       "         var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                        \n",
       "bending     0.427648    16.626693     0.726028    23.312530  \n",
       "cyclin      2.667201    16.252897     2.965306    17.244941  \n",
       "lyin        0.340598     7.208963     0.578144     9.152296  \n",
       "sittin      0.398618    14.736741     0.742544    15.974439  \n",
       "standin     0.395032    14.655550     0.610384    13.583375  \n",
       "walkin      4.302352    15.266241     3.175534    15.886737  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('ATYPE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bending</th>\n",
       "      <td>12.471234</td>\n",
       "      <td>0.563777</td>\n",
       "      <td>7.089369</td>\n",
       "      <td>0.921850</td>\n",
       "      <td>10.430987</td>\n",
       "      <td>12.471234</td>\n",
       "      <td>0.563777</td>\n",
       "      <td>7.089369</td>\n",
       "      <td>0.921850</td>\n",
       "      <td>10.430987</td>\n",
       "      <td>...</td>\n",
       "      <td>12.725044</td>\n",
       "      <td>0.564128</td>\n",
       "      <td>7.181360</td>\n",
       "      <td>0.921409</td>\n",
       "      <td>10.562791</td>\n",
       "      <td>12.807718</td>\n",
       "      <td>0.564301</td>\n",
       "      <td>7.214285</td>\n",
       "      <td>0.921230</td>\n",
       "      <td>10.606611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyclin</th>\n",
       "      <td>3.820435</td>\n",
       "      <td>1.934903</td>\n",
       "      <td>3.608886</td>\n",
       "      <td>1.710640</td>\n",
       "      <td>3.302717</td>\n",
       "      <td>3.820435</td>\n",
       "      <td>1.934903</td>\n",
       "      <td>3.608886</td>\n",
       "      <td>1.710640</td>\n",
       "      <td>3.302717</td>\n",
       "      <td>...</td>\n",
       "      <td>4.795252</td>\n",
       "      <td>1.939090</td>\n",
       "      <td>3.827658</td>\n",
       "      <td>1.722657</td>\n",
       "      <td>3.567922</td>\n",
       "      <td>5.076117</td>\n",
       "      <td>1.940822</td>\n",
       "      <td>3.894445</td>\n",
       "      <td>1.726250</td>\n",
       "      <td>3.652404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyin</th>\n",
       "      <td>7.600010</td>\n",
       "      <td>0.377088</td>\n",
       "      <td>3.847469</td>\n",
       "      <td>0.668546</td>\n",
       "      <td>5.113317</td>\n",
       "      <td>7.600010</td>\n",
       "      <td>0.377088</td>\n",
       "      <td>3.847469</td>\n",
       "      <td>0.668546</td>\n",
       "      <td>5.113317</td>\n",
       "      <td>...</td>\n",
       "      <td>8.214017</td>\n",
       "      <td>0.377359</td>\n",
       "      <td>3.881109</td>\n",
       "      <td>0.669349</td>\n",
       "      <td>5.147825</td>\n",
       "      <td>8.407166</td>\n",
       "      <td>0.377567</td>\n",
       "      <td>3.892634</td>\n",
       "      <td>0.669174</td>\n",
       "      <td>5.159684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sittin</th>\n",
       "      <td>4.158324</td>\n",
       "      <td>0.421325</td>\n",
       "      <td>5.207250</td>\n",
       "      <td>0.867719</td>\n",
       "      <td>5.003480</td>\n",
       "      <td>4.158324</td>\n",
       "      <td>0.421325</td>\n",
       "      <td>5.207250</td>\n",
       "      <td>0.867719</td>\n",
       "      <td>5.003480</td>\n",
       "      <td>...</td>\n",
       "      <td>5.276706</td>\n",
       "      <td>0.421247</td>\n",
       "      <td>5.317361</td>\n",
       "      <td>0.866731</td>\n",
       "      <td>5.146924</td>\n",
       "      <td>5.604308</td>\n",
       "      <td>0.421387</td>\n",
       "      <td>5.354299</td>\n",
       "      <td>0.866980</td>\n",
       "      <td>5.193776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standin</th>\n",
       "      <td>2.628835</td>\n",
       "      <td>0.374164</td>\n",
       "      <td>3.983268</td>\n",
       "      <td>0.722081</td>\n",
       "      <td>3.907701</td>\n",
       "      <td>2.628835</td>\n",
       "      <td>0.374164</td>\n",
       "      <td>3.983268</td>\n",
       "      <td>0.722081</td>\n",
       "      <td>3.907701</td>\n",
       "      <td>...</td>\n",
       "      <td>4.350781</td>\n",
       "      <td>0.374181</td>\n",
       "      <td>4.128552</td>\n",
       "      <td>0.721632</td>\n",
       "      <td>4.046885</td>\n",
       "      <td>4.785235</td>\n",
       "      <td>0.374366</td>\n",
       "      <td>4.178717</td>\n",
       "      <td>0.721755</td>\n",
       "      <td>4.092250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walkin</th>\n",
       "      <td>4.812406</td>\n",
       "      <td>2.444056</td>\n",
       "      <td>2.916043</td>\n",
       "      <td>1.624244</td>\n",
       "      <td>3.115523</td>\n",
       "      <td>4.812406</td>\n",
       "      <td>2.444056</td>\n",
       "      <td>2.916043</td>\n",
       "      <td>1.624244</td>\n",
       "      <td>3.115523</td>\n",
       "      <td>...</td>\n",
       "      <td>5.519083</td>\n",
       "      <td>2.461158</td>\n",
       "      <td>3.151718</td>\n",
       "      <td>1.638863</td>\n",
       "      <td>3.354381</td>\n",
       "      <td>5.730645</td>\n",
       "      <td>2.466088</td>\n",
       "      <td>3.223939</td>\n",
       "      <td>1.643607</td>\n",
       "      <td>3.430036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                         \n",
       "bending  12.471234   0.563777   7.089369   0.921850  10.430987    12.471234   \n",
       "cyclin    3.820435   1.934903   3.608886   1.710640   3.302717     3.820435   \n",
       "lyin      7.600010   0.377088   3.847469   0.668546   5.113317     7.600010   \n",
       "sittin    4.158324   0.421325   5.207250   0.867719   5.003480     4.158324   \n",
       "standin   2.628835   0.374164   3.983268   0.722081   3.907701     2.628835   \n",
       "walkin    4.812406   2.444056   2.916043   1.624244   3.115523     4.812406   \n",
       "\n",
       "         var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                        ...                \n",
       "bending     0.563777     7.089369     0.921850    10.430987  ...    12.725044   \n",
       "cyclin      1.934903     3.608886     1.710640     3.302717  ...     4.795252   \n",
       "lyin        0.377088     3.847469     0.668546     5.113317  ...     8.214017   \n",
       "sittin      0.421325     5.207250     0.867719     5.003480  ...     5.276706   \n",
       "standin     0.374164     3.983268     0.722081     3.907701  ...     4.350781   \n",
       "walkin      2.444056     2.916043     1.624244     3.115523  ...     5.519083   \n",
       "\n",
       "         var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                      \n",
       "bending     0.564128     7.181360     0.921409    10.562791    12.807718   \n",
       "cyclin      1.939090     3.827658     1.722657     3.567922     5.076117   \n",
       "lyin        0.377359     3.881109     0.669349     5.147825     8.407166   \n",
       "sittin      0.421247     5.317361     0.866731     5.146924     5.604308   \n",
       "standin     0.374181     4.128552     0.721632     4.046885     4.785235   \n",
       "walkin      2.461158     3.151718     1.638863     3.354381     5.730645   \n",
       "\n",
       "         var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                        \n",
       "bending     0.564301     7.214285     0.921230    10.606611  \n",
       "cyclin      1.940822     3.894445     1.726250     3.652404  \n",
       "lyin        0.377567     3.892634     0.669174     5.159684  \n",
       "sittin      0.421387     5.354299     0.866980     5.193776  \n",
       "standin     0.374366     4.178717     0.721755     4.092250  \n",
       "walkin      2.466088     3.223939     1.643607     3.430036  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('ATYPE').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bending</th>\n",
       "      <td>34.597288</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>17.382712</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>24.515593</td>\n",
       "      <td>34.597288</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>17.382712</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>24.515593</td>\n",
       "      <td>...</td>\n",
       "      <td>34.597288</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>17.382712</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>24.515593</td>\n",
       "      <td>34.597288</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>17.382712</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>24.515593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyclin</th>\n",
       "      <td>37.204545</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>16.170455</td>\n",
       "      <td>2.871970</td>\n",
       "      <td>18.033939</td>\n",
       "      <td>37.204545</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>16.170455</td>\n",
       "      <td>2.871970</td>\n",
       "      <td>18.033939</td>\n",
       "      <td>...</td>\n",
       "      <td>37.204545</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>16.170455</td>\n",
       "      <td>2.871970</td>\n",
       "      <td>18.033939</td>\n",
       "      <td>37.204545</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>16.170455</td>\n",
       "      <td>2.871970</td>\n",
       "      <td>18.033939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyin</th>\n",
       "      <td>40.491404</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>7.308246</td>\n",
       "      <td>0.604035</td>\n",
       "      <td>10.464912</td>\n",
       "      <td>40.491404</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>7.308246</td>\n",
       "      <td>0.604035</td>\n",
       "      <td>10.464912</td>\n",
       "      <td>...</td>\n",
       "      <td>40.491404</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>7.308246</td>\n",
       "      <td>0.604035</td>\n",
       "      <td>10.464912</td>\n",
       "      <td>40.491404</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>7.308246</td>\n",
       "      <td>0.604035</td>\n",
       "      <td>10.464912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sittin</th>\n",
       "      <td>42.306897</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>15.288448</td>\n",
       "      <td>0.866034</td>\n",
       "      <td>16.763276</td>\n",
       "      <td>42.306897</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>15.288448</td>\n",
       "      <td>0.866034</td>\n",
       "      <td>16.763276</td>\n",
       "      <td>...</td>\n",
       "      <td>41.531034</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>15.173448</td>\n",
       "      <td>0.830690</td>\n",
       "      <td>16.401207</td>\n",
       "      <td>41.531034</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>15.173448</td>\n",
       "      <td>0.830690</td>\n",
       "      <td>16.401207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standin</th>\n",
       "      <td>44.255500</td>\n",
       "      <td>0.428167</td>\n",
       "      <td>14.437167</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>14.179500</td>\n",
       "      <td>44.255500</td>\n",
       "      <td>0.428167</td>\n",
       "      <td>14.437167</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>14.179500</td>\n",
       "      <td>...</td>\n",
       "      <td>44.255500</td>\n",
       "      <td>0.428167</td>\n",
       "      <td>14.437167</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>14.179500</td>\n",
       "      <td>44.255500</td>\n",
       "      <td>0.428167</td>\n",
       "      <td>14.437167</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>14.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walkin</th>\n",
       "      <td>35.790400</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>15.501400</td>\n",
       "      <td>3.628400</td>\n",
       "      <td>16.913200</td>\n",
       "      <td>35.790400</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>15.501400</td>\n",
       "      <td>3.628400</td>\n",
       "      <td>16.913200</td>\n",
       "      <td>...</td>\n",
       "      <td>35.790400</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>15.501400</td>\n",
       "      <td>3.628400</td>\n",
       "      <td>16.913200</td>\n",
       "      <td>35.790400</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>15.501400</td>\n",
       "      <td>3.628400</td>\n",
       "      <td>16.913200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                         \n",
       "bending  34.597288   0.459831  17.382712   0.800169  24.515593    34.597288   \n",
       "cyclin   37.204545   2.430000  16.170455   2.871970  18.033939    37.204545   \n",
       "lyin     40.491404   0.392982   7.308246   0.604035  10.464912    40.491404   \n",
       "sittin   42.306897   0.370000  15.288448   0.866034  16.763276    42.306897   \n",
       "standin  44.255500   0.428167  14.437167   0.657500  14.179500    44.255500   \n",
       "walkin   35.790400   4.290000  15.501400   3.628400  16.913200    35.790400   \n",
       "\n",
       "         var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                        ...                \n",
       "bending     0.459831    17.382712     0.800169    24.515593  ...    34.597288   \n",
       "cyclin      2.430000    16.170455     2.871970    18.033939  ...    37.204545   \n",
       "lyin        0.392982     7.308246     0.604035    10.464912  ...    40.491404   \n",
       "sittin      0.370000    15.288448     0.866034    16.763276  ...    41.531034   \n",
       "standin     0.428167    14.437167     0.657500    14.179500  ...    44.255500   \n",
       "walkin      4.290000    15.501400     3.628400    16.913200  ...    35.790400   \n",
       "\n",
       "         var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                      \n",
       "bending     0.459831    17.382712     0.800169    24.515593    34.597288   \n",
       "cyclin      2.430000    16.170455     2.871970    18.033939    37.204545   \n",
       "lyin        0.392982     7.308246     0.604035    10.464912    40.491404   \n",
       "sittin      0.370000    15.173448     0.830690    16.401207    41.531034   \n",
       "standin     0.428167    14.437167     0.657500    14.179500    44.255500   \n",
       "walkin      4.290000    15.501400     3.628400    16.913200    35.790400   \n",
       "\n",
       "         var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                        \n",
       "bending     0.459831    17.382712     0.800169    24.515593  \n",
       "cyclin      2.430000    16.170455     2.871970    18.033939  \n",
       "lyin        0.392982     7.308246     0.604035    10.464912  \n",
       "sittin      0.370000    15.173448     0.830690    16.401207  \n",
       "standin     0.428167    14.437167     0.657500    14.179500  \n",
       "walkin      4.290000    15.501400     3.628400    16.913200  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('ATYPE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bending</th>\n",
       "      <td>11.936775</td>\n",
       "      <td>0.423379</td>\n",
       "      <td>6.681963</td>\n",
       "      <td>0.814495</td>\n",
       "      <td>9.677460</td>\n",
       "      <td>11.936775</td>\n",
       "      <td>0.423379</td>\n",
       "      <td>6.681963</td>\n",
       "      <td>0.814495</td>\n",
       "      <td>9.677460</td>\n",
       "      <td>...</td>\n",
       "      <td>11.936775</td>\n",
       "      <td>0.423379</td>\n",
       "      <td>6.681963</td>\n",
       "      <td>0.814495</td>\n",
       "      <td>9.677460</td>\n",
       "      <td>11.936775</td>\n",
       "      <td>0.423379</td>\n",
       "      <td>6.681963</td>\n",
       "      <td>0.814495</td>\n",
       "      <td>9.677460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyclin</th>\n",
       "      <td>3.936100</td>\n",
       "      <td>1.907624</td>\n",
       "      <td>3.280253</td>\n",
       "      <td>1.487486</td>\n",
       "      <td>3.265736</td>\n",
       "      <td>3.936100</td>\n",
       "      <td>1.907624</td>\n",
       "      <td>3.280253</td>\n",
       "      <td>1.487486</td>\n",
       "      <td>3.265736</td>\n",
       "      <td>...</td>\n",
       "      <td>3.936100</td>\n",
       "      <td>1.907624</td>\n",
       "      <td>3.280253</td>\n",
       "      <td>1.487486</td>\n",
       "      <td>3.265736</td>\n",
       "      <td>3.936100</td>\n",
       "      <td>1.907624</td>\n",
       "      <td>3.280253</td>\n",
       "      <td>1.487486</td>\n",
       "      <td>3.265736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyin</th>\n",
       "      <td>5.823699</td>\n",
       "      <td>0.243787</td>\n",
       "      <td>3.837303</td>\n",
       "      <td>0.636870</td>\n",
       "      <td>4.170597</td>\n",
       "      <td>5.823699</td>\n",
       "      <td>0.243787</td>\n",
       "      <td>3.837303</td>\n",
       "      <td>0.636870</td>\n",
       "      <td>4.170597</td>\n",
       "      <td>...</td>\n",
       "      <td>5.823699</td>\n",
       "      <td>0.243787</td>\n",
       "      <td>3.837303</td>\n",
       "      <td>0.636870</td>\n",
       "      <td>4.170597</td>\n",
       "      <td>5.823699</td>\n",
       "      <td>0.243787</td>\n",
       "      <td>3.837303</td>\n",
       "      <td>0.636870</td>\n",
       "      <td>4.170597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sittin</th>\n",
       "      <td>3.615483</td>\n",
       "      <td>0.345055</td>\n",
       "      <td>5.476327</td>\n",
       "      <td>0.897030</td>\n",
       "      <td>5.231980</td>\n",
       "      <td>3.615483</td>\n",
       "      <td>0.345055</td>\n",
       "      <td>5.476327</td>\n",
       "      <td>0.897030</td>\n",
       "      <td>5.231980</td>\n",
       "      <td>...</td>\n",
       "      <td>6.613111</td>\n",
       "      <td>0.345055</td>\n",
       "      <td>5.724878</td>\n",
       "      <td>0.889920</td>\n",
       "      <td>5.644047</td>\n",
       "      <td>6.613111</td>\n",
       "      <td>0.345055</td>\n",
       "      <td>5.724878</td>\n",
       "      <td>0.889920</td>\n",
       "      <td>5.644047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standin</th>\n",
       "      <td>2.255689</td>\n",
       "      <td>0.629720</td>\n",
       "      <td>4.169106</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>4.009013</td>\n",
       "      <td>2.255689</td>\n",
       "      <td>0.629720</td>\n",
       "      <td>4.169106</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>4.009013</td>\n",
       "      <td>...</td>\n",
       "      <td>2.255689</td>\n",
       "      <td>0.629720</td>\n",
       "      <td>4.169106</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>4.009013</td>\n",
       "      <td>2.255689</td>\n",
       "      <td>0.629720</td>\n",
       "      <td>4.169106</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>4.009013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walkin</th>\n",
       "      <td>4.045297</td>\n",
       "      <td>2.379193</td>\n",
       "      <td>2.376477</td>\n",
       "      <td>1.605666</td>\n",
       "      <td>2.512573</td>\n",
       "      <td>4.045297</td>\n",
       "      <td>2.379193</td>\n",
       "      <td>2.376477</td>\n",
       "      <td>1.605666</td>\n",
       "      <td>2.512573</td>\n",
       "      <td>...</td>\n",
       "      <td>4.045297</td>\n",
       "      <td>2.379193</td>\n",
       "      <td>2.376477</td>\n",
       "      <td>1.605666</td>\n",
       "      <td>2.512573</td>\n",
       "      <td>4.045297</td>\n",
       "      <td>2.379193</td>\n",
       "      <td>2.376477</td>\n",
       "      <td>1.605666</td>\n",
       "      <td>2.512573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                         \n",
       "bending  11.936775   0.423379   6.681963   0.814495   9.677460    11.936775   \n",
       "cyclin    3.936100   1.907624   3.280253   1.487486   3.265736     3.936100   \n",
       "lyin      5.823699   0.243787   3.837303   0.636870   4.170597     5.823699   \n",
       "sittin    3.615483   0.345055   5.476327   0.897030   5.231980     3.615483   \n",
       "standin   2.255689   0.629720   4.169106   0.854719   4.009013     2.255689   \n",
       "walkin    4.045297   2.379193   2.376477   1.605666   2.512573     4.045297   \n",
       "\n",
       "         var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                        ...                \n",
       "bending     0.423379     6.681963     0.814495     9.677460  ...    11.936775   \n",
       "cyclin      1.907624     3.280253     1.487486     3.265736  ...     3.936100   \n",
       "lyin        0.243787     3.837303     0.636870     4.170597  ...     5.823699   \n",
       "sittin      0.345055     5.476327     0.897030     5.231980  ...     6.613111   \n",
       "standin     0.629720     4.169106     0.854719     4.009013  ...     2.255689   \n",
       "walkin      2.379193     2.376477     1.605666     2.512573  ...     4.045297   \n",
       "\n",
       "         var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                      \n",
       "bending     0.423379     6.681963     0.814495     9.677460    11.936775   \n",
       "cyclin      1.907624     3.280253     1.487486     3.265736     3.936100   \n",
       "lyin        0.243787     3.837303     0.636870     4.170597     5.823699   \n",
       "sittin      0.345055     5.724878     0.889920     5.644047     6.613111   \n",
       "standin     0.629720     4.169106     0.854719     4.009013     2.255689   \n",
       "walkin      2.379193     2.376477     1.605666     2.512573     4.045297   \n",
       "\n",
       "         var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                        \n",
       "bending     0.423379     6.681963     0.814495     9.677460  \n",
       "cyclin      1.907624     3.280253     1.487486     3.265736  \n",
       "lyin        0.243787     3.837303     0.636870     4.170597  \n",
       "sittin      0.345055     5.724878     0.889920     5.644047  \n",
       "standin     0.629720     4.169106     0.854719     4.009013  \n",
       "walkin      2.379193     2.376477     1.605666     2.512573  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('ATYPE').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizamos los datos a mean= 0 y std = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = dict()\n",
    "decoder = dict()\n",
    "counter = 0\n",
    "\n",
    "for itera in train_df['ATYPE'].unique():\n",
    "    encoder[itera] = counter\n",
    "    decoder[counter] = itera\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['ATYPE'] = train_df['ATYPE'].apply(lambda x: encoder[x])\n",
    "test_df['ATYPE'] = test_df['ATYPE'].apply(lambda x: encoder[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "41883    5\n",
       "41884    5\n",
       "41885    5\n",
       "41886    5\n",
       "41887    5\n",
       "Name: ATYPE, Length: 41888, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['ATYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = list(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns.remove('ATYPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=False, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = sc(copy=False)\n",
    "scaler.fit(train_df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[columns] = scaler.transform(train_df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df[columns] = scaler.transform(test_df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.575895</td>\n",
       "      <td>-0.500222</td>\n",
       "      <td>0.459846</td>\n",
       "      <td>-0.463988</td>\n",
       "      <td>1.106898</td>\n",
       "      <td>-0.575895</td>\n",
       "      <td>-0.500222</td>\n",
       "      <td>0.459846</td>\n",
       "      <td>-0.463988</td>\n",
       "      <td>1.106898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.532057</td>\n",
       "      <td>-0.497881</td>\n",
       "      <td>0.450926</td>\n",
       "      <td>-0.461891</td>\n",
       "      <td>1.086105</td>\n",
       "      <td>-0.519429</td>\n",
       "      <td>-0.497130</td>\n",
       "      <td>0.447944</td>\n",
       "      <td>-0.461080</td>\n",
       "      <td>1.079195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.243751</td>\n",
       "      <td>0.601693</td>\n",
       "      <td>0.395822</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>-0.243751</td>\n",
       "      <td>0.601693</td>\n",
       "      <td>0.395822</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224814</td>\n",
       "      <td>0.597723</td>\n",
       "      <td>0.385914</td>\n",
       "      <td>0.904619</td>\n",
       "      <td>0.221410</td>\n",
       "      <td>-0.219566</td>\n",
       "      <td>0.597236</td>\n",
       "      <td>0.382540</td>\n",
       "      <td>0.902363</td>\n",
       "      <td>0.220416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.169412</td>\n",
       "      <td>-0.543286</td>\n",
       "      <td>-1.236753</td>\n",
       "      <td>-0.556808</td>\n",
       "      <td>-0.946862</td>\n",
       "      <td>0.169412</td>\n",
       "      <td>-0.543286</td>\n",
       "      <td>-1.236753</td>\n",
       "      <td>-0.556808</td>\n",
       "      <td>-0.946862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156550</td>\n",
       "      <td>-0.540397</td>\n",
       "      <td>-1.208972</td>\n",
       "      <td>-0.552378</td>\n",
       "      <td>-0.930425</td>\n",
       "      <td>0.152806</td>\n",
       "      <td>-0.539667</td>\n",
       "      <td>-1.199911</td>\n",
       "      <td>-0.551124</td>\n",
       "      <td>-0.924980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.422323</td>\n",
       "      <td>-0.514642</td>\n",
       "      <td>0.121054</td>\n",
       "      <td>-0.453917</td>\n",
       "      <td>0.039654</td>\n",
       "      <td>0.422323</td>\n",
       "      <td>-0.514642</td>\n",
       "      <td>0.121054</td>\n",
       "      <td>-0.453917</td>\n",
       "      <td>0.039654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390691</td>\n",
       "      <td>-0.512100</td>\n",
       "      <td>0.118262</td>\n",
       "      <td>-0.452089</td>\n",
       "      <td>0.040568</td>\n",
       "      <td>0.381303</td>\n",
       "      <td>-0.511316</td>\n",
       "      <td>0.117253</td>\n",
       "      <td>-0.451024</td>\n",
       "      <td>0.040595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.703439</td>\n",
       "      <td>-0.516291</td>\n",
       "      <td>0.106054</td>\n",
       "      <td>-0.535483</td>\n",
       "      <td>-0.305308</td>\n",
       "      <td>0.703439</td>\n",
       "      <td>-0.516291</td>\n",
       "      <td>0.106054</td>\n",
       "      <td>-0.535483</td>\n",
       "      <td>-0.305308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648820</td>\n",
       "      <td>-0.513792</td>\n",
       "      <td>0.104068</td>\n",
       "      <td>-0.532405</td>\n",
       "      <td>-0.299610</td>\n",
       "      <td>0.633094</td>\n",
       "      <td>-0.513068</td>\n",
       "      <td>0.103046</td>\n",
       "      <td>-0.531493</td>\n",
       "      <td>-0.297825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.552607</td>\n",
       "      <td>1.404641</td>\n",
       "      <td>0.216370</td>\n",
       "      <td>1.037814</td>\n",
       "      <td>0.028578</td>\n",
       "      <td>-0.552607</td>\n",
       "      <td>1.404641</td>\n",
       "      <td>0.216370</td>\n",
       "      <td>1.037814</td>\n",
       "      <td>0.028578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510400</td>\n",
       "      <td>1.398655</td>\n",
       "      <td>0.210980</td>\n",
       "      <td>1.032044</td>\n",
       "      <td>0.028466</td>\n",
       "      <td>-0.497730</td>\n",
       "      <td>1.396258</td>\n",
       "      <td>0.209901</td>\n",
       "      <td>1.030366</td>\n",
       "      <td>0.028182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                       \n",
       "0      -0.575895  -0.500222   0.459846  -0.463988   1.106898    -0.575895   \n",
       "1      -0.243751   0.601693   0.395822   0.910000   0.226360    -0.243751   \n",
       "2       0.169412  -0.543286  -1.236753  -0.556808  -0.946862     0.169412   \n",
       "3       0.422323  -0.514642   0.121054  -0.453917   0.039654     0.422323   \n",
       "4       0.703439  -0.516291   0.106054  -0.535483  -0.305308     0.703439   \n",
       "5      -0.552607   1.404641   0.216370   1.037814   0.028578    -0.552607   \n",
       "\n",
       "       var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                      ...                \n",
       "0        -0.500222     0.459846    -0.463988     1.106898  ...    -0.532057   \n",
       "1         0.601693     0.395822     0.910000     0.226360  ...    -0.224814   \n",
       "2        -0.543286    -1.236753    -0.556808    -0.946862  ...     0.156550   \n",
       "3        -0.514642     0.121054    -0.453917     0.039654  ...     0.390691   \n",
       "4        -0.516291     0.106054    -0.535483    -0.305308  ...     0.648820   \n",
       "5         1.404641     0.216370     1.037814     0.028578  ...    -0.510400   \n",
       "\n",
       "       var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                    \n",
       "0        -0.497881     0.450926    -0.461891     1.086105    -0.519429   \n",
       "1         0.597723     0.385914     0.904619     0.221410    -0.219566   \n",
       "2        -0.540397    -1.208972    -0.552378    -0.930425     0.152806   \n",
       "3        -0.512100     0.118262    -0.452089     0.040568     0.381303   \n",
       "4        -0.513792     0.104068    -0.532405    -0.299610     0.633094   \n",
       "5         1.398655     0.210980     1.032044     0.028466    -0.497730   \n",
       "\n",
       "       var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                      \n",
       "0        -0.497130     0.447944    -0.461080     1.079195  \n",
       "1         0.597236     0.382540     0.902363     0.220416  \n",
       "2        -0.539667    -1.199911    -0.551124    -0.924980  \n",
       "3        -0.511316     0.117253    -0.451024     0.040595  \n",
       "4        -0.513068     0.103046    -0.531493    -0.297825  \n",
       "5         1.396258     0.209901     1.030366     0.028182  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('ATYPE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>avg_rss12_1</th>\n",
       "      <th>var_rss12_1</th>\n",
       "      <th>avg_rss13_1</th>\n",
       "      <th>var_rss13_1</th>\n",
       "      <th>avg_rss23_1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss12_4</th>\n",
       "      <th>var_rss12_4</th>\n",
       "      <th>avg_rss13_4</th>\n",
       "      <th>var_rss13_4</th>\n",
       "      <th>avg_rss23_4</th>\n",
       "      <th>avg_rss12_5</th>\n",
       "      <th>var_rss12_5</th>\n",
       "      <th>avg_rss13_5</th>\n",
       "      <th>var_rss13_5</th>\n",
       "      <th>avg_rss23_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATYPE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.529551</td>\n",
       "      <td>-0.486287</td>\n",
       "      <td>0.571889</td>\n",
       "      <td>-0.423256</td>\n",
       "      <td>1.252751</td>\n",
       "      <td>-0.529551</td>\n",
       "      <td>-0.486287</td>\n",
       "      <td>0.571889</td>\n",
       "      <td>-0.423256</td>\n",
       "      <td>1.252751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.461954</td>\n",
       "      <td>-0.482509</td>\n",
       "      <td>0.578201</td>\n",
       "      <td>-0.417655</td>\n",
       "      <td>1.250194</td>\n",
       "      <td>-0.442113</td>\n",
       "      <td>-0.481404</td>\n",
       "      <td>0.580228</td>\n",
       "      <td>-0.415937</td>\n",
       "      <td>1.249471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.182287</td>\n",
       "      <td>0.474402</td>\n",
       "      <td>0.355196</td>\n",
       "      <td>0.837767</td>\n",
       "      <td>0.318903</td>\n",
       "      <td>-0.182287</td>\n",
       "      <td>0.474402</td>\n",
       "      <td>0.355196</td>\n",
       "      <td>0.837767</td>\n",
       "      <td>0.318903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139404</td>\n",
       "      <td>0.479702</td>\n",
       "      <td>0.364958</td>\n",
       "      <td>0.843584</td>\n",
       "      <td>0.328774</td>\n",
       "      <td>-0.126634</td>\n",
       "      <td>0.481326</td>\n",
       "      <td>0.368115</td>\n",
       "      <td>0.845533</td>\n",
       "      <td>0.332087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.255495</td>\n",
       "      <td>-0.518883</td>\n",
       "      <td>-1.228939</td>\n",
       "      <td>-0.542635</td>\n",
       "      <td>-0.771608</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>-0.518883</td>\n",
       "      <td>-1.228939</td>\n",
       "      <td>-0.542635</td>\n",
       "      <td>-0.771608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267221</td>\n",
       "      <td>-0.515156</td>\n",
       "      <td>-1.193952</td>\n",
       "      <td>-0.537055</td>\n",
       "      <td>-0.747225</td>\n",
       "      <td>0.271078</td>\n",
       "      <td>-0.514069</td>\n",
       "      <td>-1.182539</td>\n",
       "      <td>-0.535359</td>\n",
       "      <td>-0.739198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.497303</td>\n",
       "      <td>-0.530090</td>\n",
       "      <td>0.197536</td>\n",
       "      <td>-0.383166</td>\n",
       "      <td>0.135832</td>\n",
       "      <td>0.497303</td>\n",
       "      <td>-0.530090</td>\n",
       "      <td>0.197536</td>\n",
       "      <td>-0.383166</td>\n",
       "      <td>0.135832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395836</td>\n",
       "      <td>-0.526381</td>\n",
       "      <td>0.189579</td>\n",
       "      <td>-0.399076</td>\n",
       "      <td>0.096668</td>\n",
       "      <td>0.396874</td>\n",
       "      <td>-0.525300</td>\n",
       "      <td>0.193665</td>\n",
       "      <td>-0.397354</td>\n",
       "      <td>0.100998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.756840</td>\n",
       "      <td>-0.501727</td>\n",
       "      <td>0.045368</td>\n",
       "      <td>-0.510093</td>\n",
       "      <td>-0.236427</td>\n",
       "      <td>0.756840</td>\n",
       "      <td>-0.501727</td>\n",
       "      <td>0.045368</td>\n",
       "      <td>-0.510093</td>\n",
       "      <td>-0.236427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>-0.497973</td>\n",
       "      <td>0.060064</td>\n",
       "      <td>-0.504508</td>\n",
       "      <td>-0.219166</td>\n",
       "      <td>0.726535</td>\n",
       "      <td>-0.496877</td>\n",
       "      <td>0.064835</td>\n",
       "      <td>-0.502805</td>\n",
       "      <td>-0.213452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.370639</td>\n",
       "      <td>1.381370</td>\n",
       "      <td>0.235601</td>\n",
       "      <td>1.298176</td>\n",
       "      <td>0.157432</td>\n",
       "      <td>-0.370639</td>\n",
       "      <td>1.381370</td>\n",
       "      <td>0.235601</td>\n",
       "      <td>1.298176</td>\n",
       "      <td>0.157432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314352</td>\n",
       "      <td>1.388107</td>\n",
       "      <td>0.247268</td>\n",
       "      <td>1.304072</td>\n",
       "      <td>0.169452</td>\n",
       "      <td>-0.297746</td>\n",
       "      <td>1.390222</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>1.306105</td>\n",
       "      <td>0.173463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  avg_rss12_1  \\\n",
       "ATYPE                                                                       \n",
       "0      -0.529551  -0.486287   0.571889  -0.423256   1.252751    -0.529551   \n",
       "1      -0.182287   0.474402   0.355196   0.837767   0.318903    -0.182287   \n",
       "2       0.255495  -0.518883  -1.228939  -0.542635  -0.771608     0.255495   \n",
       "3       0.497303  -0.530090   0.197536  -0.383166   0.135832     0.497303   \n",
       "4       0.756840  -0.501727   0.045368  -0.510093  -0.236427     0.756840   \n",
       "5      -0.370639   1.381370   0.235601   1.298176   0.157432    -0.370639   \n",
       "\n",
       "       var_rss12_1  avg_rss13_1  var_rss13_1  avg_rss23_1  ...  avg_rss12_4  \\\n",
       "ATYPE                                                      ...                \n",
       "0        -0.486287     0.571889    -0.423256     1.252751  ...    -0.461954   \n",
       "1         0.474402     0.355196     0.837767     0.318903  ...    -0.139404   \n",
       "2        -0.518883    -1.228939    -0.542635    -0.771608  ...     0.267221   \n",
       "3        -0.530090     0.197536    -0.383166     0.135832  ...     0.395836   \n",
       "4        -0.501727     0.045368    -0.510093    -0.236427  ...     0.732886   \n",
       "5         1.381370     0.235601     1.298176     0.157432  ...    -0.314352   \n",
       "\n",
       "       var_rss12_4  avg_rss13_4  var_rss13_4  avg_rss23_4  avg_rss12_5  \\\n",
       "ATYPE                                                                    \n",
       "0        -0.482509     0.578201    -0.417655     1.250194    -0.442113   \n",
       "1         0.479702     0.364958     0.843584     0.328774    -0.126634   \n",
       "2        -0.515156    -1.193952    -0.537055    -0.747225     0.271078   \n",
       "3        -0.526381     0.189579    -0.399076     0.096668     0.396874   \n",
       "4        -0.497973     0.060064    -0.504508    -0.219166     0.726535   \n",
       "5         1.388107     0.247268     1.304072     0.169452    -0.297746   \n",
       "\n",
       "       var_rss12_5  avg_rss13_5  var_rss13_5  avg_rss23_5  \n",
       "ATYPE                                                      \n",
       "0        -0.481404     0.580228    -0.415937     1.249471  \n",
       "1         0.481326     0.368115     0.845533     0.332087  \n",
       "2        -0.514069    -1.182539    -0.535359    -0.739198  \n",
       "3        -0.525300     0.193665    -0.397354     0.100998  \n",
       "4        -0.496877     0.064835    -0.502805    -0.213452  \n",
       "5         1.390222     0.251048     1.306105     0.173463  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('ATYPE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_df[columns].to_numpy()\n",
    "y_train = to_categorical(train_df['ATYPE'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = test_df[columns].to_numpy()\n",
    "y_test = to_categorical(test_df['ATYPE'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecemos las estructuras de almacenamiento e iteraciÃ³n de nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = [32, 256]\n",
    "epochs = [25]\n",
    "perceptrons = [64, 256, 1024]\n",
    "dropout = [0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_result = {'conf': None, 'xaccuracy': None, 'yaccuracy': None, 'xloss' : None, 'yloss' : None, \n",
    "                'bepoch' : None, 'baccuracy': None, 'bloss': None}\n",
    "models_analysis = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos las clases Keras necesarias para la creacion de nuestra MLP bÃ¡sica y componemos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dimension = len(train_df.columns)-1\n",
    "output_dimension = len(train_df['ATYPE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0821 00:24:44.217809  9148 deprecation_wrapper.py:119] From C:\\Users\\jose.sanchez\\AppData\\Local\\Continuum\\anaconda3.1\\envs\\keras-tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0821 00:24:44.222809  9148 deprecation_wrapper.py:119] From C:\\Users\\jose.sanchez\\AppData\\Local\\Continuum\\anaconda3.1\\envs\\keras-tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0821 00:24:44.227782  9148 deprecation_wrapper.py:119] From C:\\Users\\jose.sanchez\\AppData\\Local\\Continuum\\anaconda3.1\\envs\\keras-tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0821 00:24:44.263690  9148 deprecation_wrapper.py:119] From C:\\Users\\jose.sanchez\\AppData\\Local\\Continuum\\anaconda3.1\\envs\\keras-tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0821 00:24:44.286626  9148 deprecation.py:506] From C:\\Users\\jose.sanchez\\AppData\\Local\\Continuum\\anaconda3.1\\envs\\keras-tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0821 00:24:44.394336  9148 deprecation_wrapper.py:119] From C:\\Users\\jose.sanchez\\AppData\\Local\\Continuum\\anaconda3.1\\envs\\keras-tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0821 00:24:44.426250  9148 deprecation_wrapper.py:119] From C:\\Users\\jose.sanchez\\AppData\\Local\\Continuum\\anaconda3.1\\envs\\keras-tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0821 00:24:44.558995  9148 deprecation.py:323] From C:\\Users\\jose.sanchez\\AppData\\Local\\Continuum\\anaconda3.1\\envs\\keras-tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 96us/step - loss: 0.7569 - acc: 0.6764\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 5s 115us/step - loss: 0.6558 - acc: 0.7115\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 4s 102us/step - loss: 0.6265 - acc: 0.7251\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 4s 92us/step - loss: 0.6084 - acc: 0.7332\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 4s 90us/step - loss: 0.5943 - acc: 0.7381\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 3s 78us/step - loss: 0.5868 - acc: 0.7448\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 5s 113us/step - loss: 0.5780 - acc: 0.7485\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 3s 75us/step - loss: 0.5691 - acc: 0.7488\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 3s 81us/step - loss: 0.5653 - acc: 0.7532\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 4s 87us/step - loss: 0.5613 - acc: 0.7531\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 3s 73us/step - loss: 0.5563 - acc: 0.7576\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 5s 112us/step - loss: 0.5519 - acc: 0.7565\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 3s 81us/step - loss: 0.5513 - acc: 0.7580\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 4s 95us/step - loss: 0.5488 - acc: 0.7585\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 4s 89us/step - loss: 0.5446 - acc: 0.7621\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 5s 111us/step - loss: 0.5444 - acc: 0.7600\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 4s 95us/step - loss: 0.5415 - acc: 0.7636\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 4s 89us/step - loss: 0.5400 - acc: 0.7608\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 3s 80us/step - loss: 0.5365 - acc: 0.7629\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 4s 106us/step - loss: 0.5357 - acc: 0.7643\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5349 - acc: 0.7637\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5325 - acc: 0.7650\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5315 - acc: 0.7658\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5331 - acc: 0.7648\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 4s 104us/step - loss: 0.5302 - acc: 0.7670\n",
      "350/350 [==============================] - 0s 336us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 1s 34us/step - loss: 0.9494 - acc: 0.6189\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 1s 25us/step - loss: 0.7425 - acc: 0.6830\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 1s 27us/step - loss: 0.6973 - acc: 0.6960\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 1s 25us/step - loss: 0.6673 - acc: 0.7079\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 1s 25us/step - loss: 0.6500 - acc: 0.7140\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 1s 24us/step - loss: 0.6352 - acc: 0.7200\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 1s 21us/step - loss: 0.6243 - acc: 0.7280\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 1s 21us/step - loss: 0.6171 - acc: 0.7299\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 1s 20us/step - loss: 0.6097 - acc: 0.7334\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 1s 23us/step - loss: 0.6040 - acc: 0.7362\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 2s 48us/step - loss: 0.5983 - acc: 0.7395\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 1s 24us/step - loss: 0.5927 - acc: 0.7417\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 1s 22us/step - loss: 0.5878 - acc: 0.7420\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 1s 21us/step - loss: 0.5835 - acc: 0.7466\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 1s 19us/step - loss: 0.5800 - acc: 0.7480\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 1s 21us/step - loss: 0.5771 - acc: 0.7462\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 1s 19us/step - loss: 0.5731 - acc: 0.7480\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 1s 19us/step - loss: 0.5710 - acc: 0.7498\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 1s 21us/step - loss: 0.5696 - acc: 0.7514\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 1s 19us/step - loss: 0.5661 - acc: 0.7533\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 1s 19us/step - loss: 0.5631 - acc: 0.7516\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 2s 45us/step - loss: 0.5629 - acc: 0.7528\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 3s 84us/step - loss: 0.5586 - acc: 0.7564\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 5s 114us/step - loss: 0.5590 - acc: 0.7566\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5574 - acc: 0.7565\n",
      "350/350 [==============================] - 0s 305us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 14s 329us/step - loss: 0.7280 - acc: 0.6859\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 6s 150us/step - loss: 0.6332 - acc: 0.7203\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 5s 131us/step - loss: 0.6076 - acc: 0.7315\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 7s 169us/step - loss: 0.5880 - acc: 0.7408\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 6s 140us/step - loss: 0.5754 - acc: 0.7470\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 5s 125us/step - loss: 0.5672 - acc: 0.7515\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 5s 127us/step - loss: 0.5584 - acc: 0.7547\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 8s 185us/step - loss: 0.5540 - acc: 0.7564\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 5s 115us/step - loss: 0.5470 - acc: 0.7595\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 5s 129us/step - loss: 0.5401 - acc: 0.7622\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 7s 156us/step - loss: 0.5384 - acc: 0.7644\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 5s 127us/step - loss: 0.5330 - acc: 0.7669\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 4s 107us/step - loss: 0.5308 - acc: 0.7671\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 7s 173us/step - loss: 0.5298 - acc: 0.7684\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 5s 116us/step - loss: 0.5245 - acc: 0.7692\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 5s 114us/step - loss: 0.5240 - acc: 0.7721\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 6s 136us/step - loss: 0.5197 - acc: 0.7739\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 5s 114us/step - loss: 0.5191 - acc: 0.7727\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 5s 129us/step - loss: 0.5165 - acc: 0.7746\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 6s 146us/step - loss: 0.5145 - acc: 0.7750\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 6s 132us/step - loss: 0.5137 - acc: 0.7765\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 5s 122us/step - loss: 0.5112 - acc: 0.7770\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 7s 159us/step - loss: 0.5098 - acc: 0.7787\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 5s 122us/step - loss: 0.5092 - acc: 0.7776\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 5s 117us/step - loss: 0.5060 - acc: 0.7809\n",
      "350/350 [==============================] - 0s 419us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 3s 74us/step - loss: 0.8354 - acc: 0.6524\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 1s 36us/step - loss: 0.6928 - acc: 0.6992\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 1s 29us/step - loss: 0.6561 - acc: 0.7141\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 3s 76us/step - loss: 0.6333 - acc: 0.7213\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 5s 127us/step - loss: 0.6199 - acc: 0.7272\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 11s 262us/step - loss: 0.6066 - acc: 0.7334\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 5s 113us/step - loss: 0.6004 - acc: 0.7356\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5911 - acc: 0.7412\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5838 - acc: 0.7449\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 3s 82us/step - loss: 0.5751 - acc: 0.7484\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 4s 91us/step - loss: 0.5718 - acc: 0.7490\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5668 - acc: 0.7511\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 1s 33us/step - loss: 0.5628 - acc: 0.7522\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5602 - acc: 0.7546\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5555 - acc: 0.7565\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 1s 25us/step - loss: 0.5517 - acc: 0.7591\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 1s 23us/step - loss: 0.5482 - acc: 0.7595\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 1s 29us/step - loss: 0.5484 - acc: 0.7580\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 1s 34us/step - loss: 0.5440 - acc: 0.7618\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 2s 41us/step - loss: 0.5420 - acc: 0.7632\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5400 - acc: 0.7627\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 1s 31us/step - loss: 0.5393 - acc: 0.7632\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 1s 24us/step - loss: 0.5350 - acc: 0.7655\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 1s 25us/step - loss: 0.5344 - acc: 0.7657\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 1s 24us/step - loss: 0.5309 - acc: 0.7658\n",
      "350/350 [==============================] - 0s 428us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 10s 238us/step - loss: 0.7062 - acc: 0.6917\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 6s 150us/step - loss: 0.6138 - acc: 0.7296\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 11s 252us/step - loss: 0.5836 - acc: 0.7420\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 6s 152us/step - loss: 0.5678 - acc: 0.7492\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 7s 169us/step - loss: 0.5588 - acc: 0.7528\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 8s 184us/step - loss: 0.5510 - acc: 0.7557\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 7s 159us/step - loss: 0.5436 - acc: 0.7625\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 8s 188us/step - loss: 0.5412 - acc: 0.7614\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 6s 146us/step - loss: 0.5346 - acc: 0.7648\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 9s 210us/step - loss: 0.5326 - acc: 0.7676\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 6s 143us/step - loss: 0.5255 - acc: 0.7683\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 7s 176us/step - loss: 0.5233 - acc: 0.7708\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 8s 200us/step - loss: 0.5201 - acc: 0.7711\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 7s 169us/step - loss: 0.5161 - acc: 0.7736\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 6s 148us/step - loss: 0.5123 - acc: 0.7755\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 6s 151us/step - loss: 0.5107 - acc: 0.7769\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 8s 188us/step - loss: 0.5094 - acc: 0.7748\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 6s 146us/step - loss: 0.5057 - acc: 0.7793\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 15s 370us/step - loss: 0.5031 - acc: 0.7798\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 13s 312us/step - loss: 0.5002 - acc: 0.7809\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 7s 164us/step - loss: 0.5002 - acc: 0.7799\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 7s 164us/step - loss: 0.4980 - acc: 0.7808\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 6s 151us/step - loss: 0.4947 - acc: 0.7851\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 7s 172us/step - loss: 0.4946 - acc: 0.7858\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 9s 207us/step - loss: 0.4926 - acc: 0.7838\n",
      "350/350 [==============================] - 1s 2ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 89us/step - loss: 0.7938 - acc: 0.6674\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 7s 161us/step - loss: 0.6661 - acc: 0.7106\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 7s 173us/step - loss: 0.6318 - acc: 0.7216\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 7s 171us/step - loss: 0.6136 - acc: 0.7293\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 2s 58us/step - loss: 0.5986 - acc: 0.7382\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 2s 52us/step - loss: 0.5836 - acc: 0.7447\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 2s 54us/step - loss: 0.5752 - acc: 0.7482\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 3s 82us/step - loss: 0.5649 - acc: 0.7538\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 2s 58us/step - loss: 0.5595 - acc: 0.7529\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 2s 48us/step - loss: 0.5539 - acc: 0.7590\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 2s 56us/step - loss: 0.5484 - acc: 0.7602\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 3s 60us/step - loss: 0.5454 - acc: 0.7594\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 2s 56us/step - loss: 0.5415 - acc: 0.7613\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 2s 53us/step - loss: 0.5367 - acc: 0.7640\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 3s 66us/step - loss: 0.5343 - acc: 0.7641\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 2s 52us/step - loss: 0.5300 - acc: 0.7675\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 2s 47us/step - loss: 0.5296 - acc: 0.7676\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 2s 57us/step - loss: 0.5256 - acc: 0.7692\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 2s 60us/step - loss: 0.5224 - acc: 0.7721\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 2s 58us/step - loss: 0.5195 - acc: 0.7724\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 3s 69us/step - loss: 0.5181 - acc: 0.7753\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 3s 63us/step - loss: 0.5171 - acc: 0.7722\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5139 - acc: 0.7751\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 10s 230us/step - loss: 0.5160 - acc: 0.7743\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 7s 172us/step - loss: 0.5119 - acc: 0.7752 1s - loss: 0.5128 - \n",
      "350/350 [==============================] - 0s 484us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 10s 242us/step - loss: 0.7213 - acc: 0.6887\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 6s 144us/step - loss: 0.6363 - acc: 0.7185\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 8s 198us/step - loss: 0.6095 - acc: 0.7296\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 7s 163us/step - loss: 0.5900 - acc: 0.7393\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 16s 376us/step - loss: 0.5763 - acc: 0.7461\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 14s 330us/step - loss: 0.5682 - acc: 0.7510\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 8s 181us/step - loss: 0.5581 - acc: 0.7549\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 9s 208us/step - loss: 0.5532 - acc: 0.7583\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 5s 109us/step - loss: 0.5482 - acc: 0.7586\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 7s 175us/step - loss: 0.5446 - acc: 0.7593\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 5s 122us/step - loss: 0.5428 - acc: 0.7636\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 6s 146us/step - loss: 0.5391 - acc: 0.7626\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 5s 112us/step - loss: 0.5375 - acc: 0.7649\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 5s 110us/step - loss: 0.5336 - acc: 0.7666\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 4s 91us/step - loss: 0.5320 - acc: 0.7670\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 4s 89us/step - loss: 0.5292 - acc: 0.7696\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 11s 253us/step - loss: 0.5294 - acc: 0.7691\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 7s 159us/step - loss: 0.5254 - acc: 0.7720\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 7s 156us/step - loss: 0.5220 - acc: 0.7728\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 6s 138us/step - loss: 0.5196 - acc: 0.7740\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 4s 100us/step - loss: 0.5184 - acc: 0.7735\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 13s 311us/step - loss: 0.5166 - acc: 0.7750\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 10s 233us/step - loss: 0.5165 - acc: 0.7770\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 7s 157us/step - loss: 0.5155 - acc: 0.7744\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 6s 132us/step - loss: 0.5131 - acc: 0.7767\n",
      "350/350 [==============================] - 0s 624us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 87us/step - loss: 0.8404 - acc: 0.6519\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 2s 54us/step - loss: 0.6907 - acc: 0.7010\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 1s 19us/step - loss: 0.6524 - acc: 0.7129\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 1s 20us/step - loss: 0.6326 - acc: 0.7215\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 1s 20us/step - loss: 0.6194 - acc: 0.7259\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 1s 20us/step - loss: 0.6083 - acc: 0.7309\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 1s 20us/step - loss: 0.5993 - acc: 0.7351\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 1s 19us/step - loss: 0.5912 - acc: 0.7393\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 1s 19us/step - loss: 0.5850 - acc: 0.7405\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 1s 18us/step - loss: 0.5784 - acc: 0.7450\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 1s 27us/step - loss: 0.5735 - acc: 0.7475\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 1s 32us/step - loss: 0.5679 - acc: 0.7475\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 1s 20us/step - loss: 0.5644 - acc: 0.7493\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 1s 20us/step - loss: 0.5619 - acc: 0.7523\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 1s 20us/step - loss: 0.5567 - acc: 0.7554\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 1s 32us/step - loss: 0.5540 - acc: 0.7549\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 1s 23us/step - loss: 0.5500 - acc: 0.7576\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 1s 21us/step - loss: 0.5474 - acc: 0.7584\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 1s 22us/step - loss: 0.5461 - acc: 0.7604\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 1s 22us/step - loss: 0.5440 - acc: 0.7610\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 1s 24us/step - loss: 0.5405 - acc: 0.7640\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 1s 21us/step - loss: 0.5411 - acc: 0.7594\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 1s 22us/step - loss: 0.5367 - acc: 0.7645\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 1s 21us/step - loss: 0.5354 - acc: 0.7643\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 1s 20us/step - loss: 0.5349 - acc: 0.7670\n",
      "350/350 [==============================] - 0s 567us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 13s 301us/step - loss: 0.7022 - acc: 0.69650s \n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 20s 469us/step - loss: 0.6125 - acc: 0.7286\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 8s 185us/step - loss: 0.5831 - acc: 0.7442\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 6s 140us/step - loss: 0.5644 - acc: 0.7519\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 8s 192us/step - loss: 0.5536 - acc: 0.7545\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 5s 119us/step - loss: 0.5457 - acc: 0.7582\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 6s 131us/step - loss: 0.5387 - acc: 0.7623\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 6s 140us/step - loss: 0.5345 - acc: 0.7627\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 6s 148us/step - loss: 0.5268 - acc: 0.7693\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 8s 183us/step - loss: 0.5233 - acc: 0.7692\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 20s 474us/step - loss: 0.5191 - acc: 0.7730\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 6s 134us/step - loss: 0.5159 - acc: 0.7750\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 6s 150us/step - loss: 0.5128 - acc: 0.7751\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 5s 128us/step - loss: 0.5101 - acc: 0.7791\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 6s 146us/step - loss: 0.5071 - acc: 0.7783\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 7s 156us/step - loss: 0.5047 - acc: 0.7791\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 5s 115us/step - loss: 0.5017 - acc: 0.7826\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 5s 129us/step - loss: 0.4996 - acc: 0.7829\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 6s 151us/step - loss: 0.4973 - acc: 0.7842\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 7s 160us/step - loss: 0.4961 - acc: 0.7839\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 7s 156us/step - loss: 0.4927 - acc: 0.7851\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 5s 123us/step - loss: 0.4920 - acc: 0.7864\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 5s 126us/step - loss: 0.4893 - acc: 0.7861\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 12s 292us/step - loss: 0.4895 - acc: 0.7860\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 21s 509us/step - loss: 0.4868 - acc: 0.78914s - - ETA: 2s - loss: 0\n",
      "350/350 [==============================] - 1s 3ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 5s 113us/step - loss: 0.7786 - acc: 0.6727\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 3s 63us/step - loss: 0.6608 - acc: 0.7124: 1s - lo\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 2s 44us/step - loss: 0.6278 - acc: 0.7241\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 1s 33us/step - loss: 0.6085 - acc: 0.7313\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 1s 27us/step - loss: 0.5927 - acc: 0.7409\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 1s 28us/step - loss: 0.5800 - acc: 0.7459\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 2s 54us/step - loss: 0.5713 - acc: 0.7478\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 2s 52us/step - loss: 0.5614 - acc: 0.7539\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 1s 33us/step - loss: 0.5538 - acc: 0.7574\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 1s 31us/step - loss: 0.5504 - acc: 0.7578\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 1s 27us/step - loss: 0.5450 - acc: 0.7592\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 1s 27us/step - loss: 0.5389 - acc: 0.7626\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5362 - acc: 0.7662\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5332 - acc: 0.7657\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 1s 26us/step - loss: 0.5299 - acc: 0.7681\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 1s 27us/step - loss: 0.5257 - acc: 0.7684\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 1s 27us/step - loss: 0.5261 - acc: 0.7702\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 5s 109us/step - loss: 0.5213 - acc: 0.7719\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 1s 33us/step - loss: 0.5167 - acc: 0.7737\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 1s 31us/step - loss: 0.5169 - acc: 0.7747\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 2s 40us/step - loss: 0.5156 - acc: 0.7744\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 2s 37us/step - loss: 0.5155 - acc: 0.7743\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 1s 32us/step - loss: 0.5103 - acc: 0.7773\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 2s 37us/step - loss: 0.5102 - acc: 0.7760: 0s - loss: 0.5064 - ac\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 2s 38us/step - loss: 0.5065 - acc: 0.7765\n",
      "350/350 [==============================] - 0s 849us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 13s 319us/step - loss: 0.6948 - acc: 0.6979\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 12s 284us/step - loss: 0.6059 - acc: 0.7346\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 12s 294us/step - loss: 0.5747 - acc: 0.7455\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 11s 251us/step - loss: 0.5591 - acc: 0.7534\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 11s 257us/step - loss: 0.5491 - acc: 0.7584\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 10s 244us/step - loss: 0.5406 - acc: 0.7631\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 10s 229us/step - loss: 0.5345 - acc: 0.7670\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 14s 323us/step - loss: 0.5303 - acc: 0.7658\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 27s 642us/step - loss: 0.5231 - acc: 0.7710\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 10s 233us/step - loss: 0.5181 - acc: 0.7725\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 11s 256us/step - loss: 0.5158 - acc: 0.7755\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 18s 424us/step - loss: 0.5088 - acc: 0.77900s - loss: 0\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 14s 330us/step - loss: 0.5057 - acc: 0.7780\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 11s 271us/step - loss: 0.5044 - acc: 0.7777\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 9s 216us/step - loss: 0.5009 - acc: 0.7810\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 11s 259us/step - loss: 0.5000 - acc: 0.7818\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 9s 210us/step - loss: 0.4958 - acc: 0.7844\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 11s 271us/step - loss: 0.4920 - acc: 0.78401s - loss: 0.4\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 12s 285us/step - loss: 0.4914 - acc: 0.7861\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 12s 284us/step - loss: 0.4902 - acc: 0.7865\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 10s 249us/step - loss: 0.4875 - acc: 0.7863\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 23s 545us/step - loss: 0.4830 - acc: 0.7897\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 12s 279us/step - loss: 0.4824 - acc: 0.7906\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 12s 278us/step - loss: 0.4809 - acc: 0.7903\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 12s 281us/step - loss: 0.4774 - acc: 0.7926\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 100us/step - loss: 0.7474 - acc: 0.6790\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.6411 - acc: 0.7177: 0s - loss:\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 4s 90us/step - loss: 0.6117 - acc: 0.7308\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 3s 74us/step - loss: 0.5888 - acc: 0.7415\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 3s 75us/step - loss: 0.5731 - acc: 0.7472\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 3s 77us/step - loss: 0.5585 - acc: 0.7553\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 4s 88us/step - loss: 0.5529 - acc: 0.7557\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 4s 90us/step - loss: 0.5464 - acc: 0.7565: 0s - loss: 0.5468 \n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5377 - acc: 0.7633\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 3s 81us/step - loss: 0.5341 - acc: 0.7636\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 3s 76us/step - loss: 0.5264 - acc: 0.7676\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 4s 100us/step - loss: 0.5255 - acc: 0.7700\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5207 - acc: 0.7719\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 3s 72us/step - loss: 0.5180 - acc: 0.7721\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5128 - acc: 0.7749\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 3s 83us/step - loss: 0.5104 - acc: 0.7762\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 4s 91us/step - loss: 0.5091 - acc: 0.7764\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 3s 78us/step - loss: 0.5070 - acc: 0.7775\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 3s 81us/step - loss: 0.5073 - acc: 0.7781\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 3s 75us/step - loss: 0.5005 - acc: 0.7824: 1s -\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 4s 104us/step - loss: 0.4989 - acc: 0.7820\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 4s 90us/step - loss: 0.4966 - acc: 0.7830\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.4931 - acc: 0.7845\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 3s 76us/step - loss: 0.4910 - acc: 0.7870\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 4s 85us/step - loss: 0.4903 - acc: 0.7854\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 9s 218us/step - loss: 0.7089 - acc: 0.6921\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 9s 208us/step - loss: 0.6189 - acc: 0.7268\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 8s 186us/step - loss: 0.5935 - acc: 0.7366\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 11s 256us/step - loss: 0.5763 - acc: 0.74583s - loss:\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 9s 211us/step - loss: 0.5643 - acc: 0.7514\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 9s 206us/step - loss: 0.5566 - acc: 0.7518\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 29s 681us/step - loss: 0.5510 - acc: 0.7578\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 11s 270us/step - loss: 0.5443 - acc: 0.7620\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 9s 204us/step - loss: 0.5400 - acc: 0.7615\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 11s 251us/step - loss: 0.5371 - acc: 0.7638\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 8s 196us/step - loss: 0.5330 - acc: 0.7652\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 10s 249us/step - loss: 0.5285 - acc: 0.7685\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 8s 194us/step - loss: 0.5296 - acc: 0.7674\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 9s 216us/step - loss: 0.5233 - acc: 0.7701\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 9s 220us/step - loss: 0.5215 - acc: 0.7729\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 8s 183us/step - loss: 0.5201 - acc: 0.7732\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 7s 173us/step - loss: 0.5167 - acc: 0.7751\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 7s 178us/step - loss: 0.5143 - acc: 0.7768\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 8s 200us/step - loss: 0.5134 - acc: 0.7750\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 8s 181us/step - loss: 0.5103 - acc: 0.7766\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 8s 192us/step - loss: 0.5071 - acc: 0.7775\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 7s 171us/step - loss: 0.5080 - acc: 0.7796\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 20s 482us/step - loss: 0.5090 - acc: 0.7794\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 7s 169us/step - loss: 0.5051 - acc: 0.7796\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 8s 191us/step - loss: 0.5043 - acc: 0.7795\n",
      "350/350 [==============================] - 0s 925us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 105us/step - loss: 0.7725 - acc: 0.6689\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 2s 47us/step - loss: 0.6523 - acc: 0.7157\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 3s 66us/step - loss: 0.6189 - acc: 0.7288\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 2s 47us/step - loss: 0.5998 - acc: 0.7388\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 2s 47us/step - loss: 0.5862 - acc: 0.7430\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 2s 48us/step - loss: 0.5746 - acc: 0.7465\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 2s 47us/step - loss: 0.5663 - acc: 0.7508\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 2s 46us/step - loss: 0.5572 - acc: 0.7555\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 2s 46us/step - loss: 0.5536 - acc: 0.7553\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 2s 50us/step - loss: 0.5466 - acc: 0.7583\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 3s 62us/step - loss: 0.5439 - acc: 0.7593: 2s -  - ETA: 0s - loss: 0.5476 -\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 2s 46us/step - loss: 0.5416 - acc: 0.7618\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 2s 47us/step - loss: 0.5345 - acc: 0.7645\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 2s 47us/step - loss: 0.5333 - acc: 0.7655\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 2s 49us/step - loss: 0.5293 - acc: 0.7681\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 2s 47us/step - loss: 0.5282 - acc: 0.7674\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 2s 46us/step - loss: 0.5242 - acc: 0.7711\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 2s 55us/step - loss: 0.5239 - acc: 0.7711\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 2s 58us/step - loss: 0.5196 - acc: 0.7714\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 2s 46us/step - loss: 0.5192 - acc: 0.7744\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 2s 47us/step - loss: 0.5170 - acc: 0.7728: 1\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 2s 46us/step - loss: 0.5152 - acc: 0.7743\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 2s 46us/step - loss: 0.5107 - acc: 0.7760\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 2s 46us/step - loss: 0.5108 - acc: 0.7755\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 2s 48us/step - loss: 0.5071 - acc: 0.7785\n",
      "350/350 [==============================] - 0s 964us/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 12s 284us/step - loss: 0.6972 - acc: 0.69480s - loss: 0.6985 - acc: 0.\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 13s 305us/step - loss: 0.6069 - acc: 0.7314\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 13s 305us/step - loss: 0.5757 - acc: 0.7474\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 13s 304us/step - loss: 0.5607 - acc: 0.75390s - loss: 0.5613 - acc:\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 13s 312us/step - loss: 0.5515 - acc: 0.7562\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 32s 772us/step - loss: 0.5430 - acc: 0.7583\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 13s 298us/step - loss: 0.5365 - acc: 0.7636\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 16s 380us/step - loss: 0.5334 - acc: 0.7667\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 13s 321us/step - loss: 0.5259 - acc: 0.7687\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 14s 330us/step - loss: 0.5231 - acc: 0.7693\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 14s 345us/step - loss: 0.5180 - acc: 0.7728\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 18s 430us/step - loss: 0.5127 - acc: 0.7767\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 15s 358us/step - loss: 0.5125 - acc: 0.77621s - loss: 0.5117 - acc: 0.77 - ETA: 1s\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 15s 347us/step - loss: 0.5071 - acc: 0.7798\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 14s 340us/step - loss: 0.5065 - acc: 0.7811\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 11s 274us/step - loss: 0.5028 - acc: 0.7795\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 14s 337us/step - loss: 0.5000 - acc: 0.7831\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 13s 320us/step - loss: 0.4986 - acc: 0.7821\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 22s 515us/step - loss: 0.4954 - acc: 0.7839\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 21s 496us/step - loss: 0.4923 - acc: 0.7857\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 14s 331us/step - loss: 0.4914 - acc: 0.7871\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 15s 361us/step - loss: 0.4888 - acc: 0.7862\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 11s 259us/step - loss: 0.4861 - acc: 0.7874\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 12s 293us/step - loss: 0.4867 - acc: 0.7880\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 15s 361us/step - loss: 0.4826 - acc: 0.7886\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 4s 100us/step - loss: 0.7514 - acc: 0.6829 2s - loss\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 4s 85us/step - loss: 0.6427 - acc: 0.7181: 0s - loss: 0.646\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 4s 94us/step - loss: 0.6094 - acc: 0.7301\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 4s 96us/step - loss: 0.5867 - acc: 0.7415\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 9s 203us/step - loss: 0.5737 - acc: 0.7460\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 7s 158us/step - loss: 0.5590 - acc: 0.7537\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5531 - acc: 0.7557\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 4s 84us/step - loss: 0.5477 - acc: 0.7579\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 4s 105us/step - loss: 0.5361 - acc: 0.7632\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 4s 106us/step - loss: 0.5332 - acc: 0.7653\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 3s 74us/step - loss: 0.5305 - acc: 0.7683\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 3s 74us/step - loss: 0.5266 - acc: 0.7656\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 4s 90us/step - loss: 0.5225 - acc: 0.7713\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 3s 80us/step - loss: 0.5177 - acc: 0.7729: 0s - loss: 0.5185 - acc: 0. - ETA: 0s - loss: 0.5184 - a\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 3s 82us/step - loss: 0.5146 - acc: 0.7743: 1s - lo\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 3s 79us/step - loss: 0.5126 - acc: 0.7764\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 3s 73us/step - loss: 0.5073 - acc: 0.7763\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 3s 81us/step - loss: 0.5074 - acc: 0.7786: 2s - loss: 0.5102 - ETA: 1s  - ETA: 0s - loss: 0.5068 - acc: 0.\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 3s 64us/step - loss: 0.5040 - acc: 0.7786: 0s - loss: 0.50\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 3s 63us/step - loss: 0.5010 - acc: 0.7823\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 3s 71us/step - loss: 0.5001 - acc: 0.7828\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 4s 94us/step - loss: 0.4997 - acc: 0.7828\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 5s 118us/step - loss: 0.4957 - acc: 0.7844 1s \n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 3s 83us/step - loss: 0.4943 - acc: 0.7861\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 3s 71us/step - loss: 0.4919 - acc: 0.7865\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 46s 1ms/step - loss: 0.6944 - acc: 0.6960: 0s - loss: 0.6962 - acc\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 25s 597us/step - loss: 0.6051 - acc: 0.7322\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 27s 651us/step - loss: 0.5735 - acc: 0.7463\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 27s 652us/step - loss: 0.5574 - acc: 0.7533\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 28s 658us/step - loss: 0.5463 - acc: 0.7595\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 23s 546us/step - loss: 0.5381 - acc: 0.7645\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - ETA: 0s - loss: 0.5312 - acc: 0.767 - 28s 672us/step - loss: 0.5313 - acc: 0.7677\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 52s 1ms/step - loss: 0.5258 - acc: 0.7694\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 27s 643us/step - loss: 0.5207 - acc: 0.77430s - loss: 0.5215 -\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 28s 664us/step - loss: 0.5168 - acc: 0.77333s - loss \n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 26s 624us/step - loss: 0.5130 - acc: 0.7767\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 27s 645us/step - loss: 0.5086 - acc: 0.7789\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 27s 654us/step - loss: 0.5076 - acc: 0.77841s -\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 26s 624us/step - loss: 0.5032 - acc: 0.7811\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 39s 920us/step - loss: 0.4998 - acc: 0.7815\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 31s 741us/step - loss: 0.4974 - acc: 0.7836\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 32s 775us/step - loss: 0.4961 - acc: 0.7842\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 25s 601us/step - loss: 0.4919 - acc: 0.7857\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 37s 874us/step - loss: 0.4893 - acc: 0.7861\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 27s 648us/step - loss: 0.4860 - acc: 0.7887\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 44s 1ms/step - loss: 0.4859 - acc: 0.7872\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 28s 662us/step - loss: 0.4831 - acc: 0.7887\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 28s 657us/step - loss: 0.4819 - acc: 0.7902\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 28s 660us/step - loss: 0.4785 - acc: 0.79114s - loss: 0.47 - ETA: 3s - lo\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 29s 682us/step - loss: 0.4777 - acc: 0.7900\n",
      "350/350 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 9s 203us/step - loss: 0.7319 - acc: 0.6831\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 7s 169us/step - loss: 0.6275 - acc: 0.7221\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 7s 165us/step - loss: 0.5962 - acc: 0.7377\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 8s 190us/step - loss: 0.5716 - acc: 0.7478\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 7s 177us/step - loss: 0.5572 - acc: 0.7539\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 8s 183us/step - loss: 0.5485 - acc: 0.7596\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 14s 326us/step - loss: 0.5406 - acc: 0.7633\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 11s 269us/step - loss: 0.5310 - acc: 0.7648\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 8s 197us/step - loss: 0.5245 - acc: 0.7716\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 7s 159us/step - loss: 0.5222 - acc: 0.7710\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 8s 182us/step - loss: 0.5155 - acc: 0.7742\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 10s 229us/step - loss: 0.5134 - acc: 0.7741\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 13s 315us/step - loss: 0.5111 - acc: 0.7763\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 8s 186us/step - loss: 0.5055 - acc: 0.7784\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - ETA: 0s - loss: 0.5023 - acc: 0.779 - 8s 198us/step - loss: 0.5023 - acc: 0.7789\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - ETA: 0s - loss: 0.4980 - acc: 0.782 - 8s 198us/step - loss: 0.4983 - acc: 0.7819\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 9s 213us/step - loss: 0.4962 - acc: 0.7823\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 9s 211us/step - loss: 0.4929 - acc: 0.7854\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 11s 261us/step - loss: 0.4895 - acc: 0.7870\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - 12s 287us/step - loss: 0.4892 - acc: 0.7854\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 12s 298us/step - loss: 0.4871 - acc: 0.7889\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 11s 274us/step - loss: 0.4850 - acc: 0.78853s - ETA: 0s - loss: 0.4835 -\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 12s 297us/step - loss: 0.4829 - acc: 0.7888\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 15s 351us/step - loss: 0.4803 - acc: 0.7909\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 16s 390us/step - loss: 0.4777 - acc: 0.7906\n",
      "350/350 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "for hl1 in perceptrons:\n",
    "    for hl2 in perceptrons:\n",
    "        for bs in batch_size:\n",
    "            for ep in epochs:\n",
    "                for dp in dropout:\n",
    "                    model = Sequential()\n",
    "                    model.add(Dense(hl1, input_shape=(input_dimension,)))\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(Dropout(dp))\n",
    "                    model.add(Dense(hl2))\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(Dropout(dp))\n",
    "                    model.add(Dense(output_dimension))\n",
    "                    model.add(Activation('softmax'))\n",
    "\n",
    "                    mr = model_result.copy()\n",
    "                    mr['conf'] = [hl1, hl2, bs, ep, dp]            \n",
    "\n",
    "                    # loss function for one-hot vector\n",
    "                    # use of adam optimizer\n",
    "                    # accuracy is a good metric for classification tasks\n",
    "                    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "                    # train the network\n",
    "                    model_history = model.fit(x=x_train, y=y_train, batch_size=bs, epochs=ep)\n",
    "                    index_acc = argmax(model_history.history['acc'])\n",
    "                    mr['bloss'] = model_history.history['loss'][-1]\n",
    "                    mr['baccuracy'] = model_history.history['acc'][-1]\n",
    "                    mr['bepoch']= index_acc + 1\n",
    "                    mr['xloss'] = model_history.history['loss'][index_acc]\n",
    "                    mr['xaccuracy'] = model_history.history['acc'][index_acc]\n",
    "\n",
    "                    # Evaluate the network                                                             \n",
    "                    mr['yloss'], mr['yaccuracy'] = model.evaluate(x_test,y_test, batch_size=bs)\n",
    "                    models_analysis.append(mr)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP best network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conf': [256, 1024, 32, 25, 0.05], 'xaccuracy': 0.7926136363636364, 'yaccuracy': 0.7999999989782061, 'xloss': 0.477423555904258, 'yloss': 0.4944298802103315, 'bepoch': 25, 'baccuracy': 0.7926136363636364, 'bloss': 0.477423555904258}\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "\n",
    "for itera in models_analysis:\n",
    "    if best_model is None:\n",
    "        best_model = itera\n",
    "    elif itera['baccuracy'] > best_model['baccuracy']:\n",
    "        best_model = itera\n",
    "\n",
    "print (best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing code MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "41888/41888 [==============================] - 36s 870us/step - loss: 0.6964 - acc: 0.6979\n",
      "Epoch 2/25\n",
      "41888/41888 [==============================] - 30s 709us/step - loss: 0.6080 - acc: 0.7318\n",
      "Epoch 3/25\n",
      "41888/41888 [==============================] - 33s 778us/step - loss: 0.5756 - acc: 0.7444\n",
      "Epoch 4/25\n",
      "41888/41888 [==============================] - 26s 620us/step - loss: 0.5593 - acc: 0.7536\n",
      "Epoch 5/25\n",
      "41888/41888 [==============================] - 26s 611us/step - loss: 0.5492 - acc: 0.75760s - loss: 0.5485 - acc\n",
      "Epoch 6/25\n",
      "41888/41888 [==============================] - 56s 1ms/step - loss: 0.5408 - acc: 0.7622\n",
      "Epoch 7/25\n",
      "41888/41888 [==============================] - 31s 733us/step - loss: 0.5356 - acc: 0.7630\n",
      "Epoch 8/25\n",
      "41888/41888 [==============================] - 15s 356us/step - loss: 0.5256 - acc: 0.7693\n",
      "Epoch 9/25\n",
      "41888/41888 [==============================] - 11s 262us/step - loss: 0.5234 - acc: 0.7698\n",
      "Epoch 10/25\n",
      "41888/41888 [==============================] - 12s 276us/step - loss: 0.5204 - acc: 0.7727\n",
      "Epoch 11/25\n",
      "41888/41888 [==============================] - 13s 307us/step - loss: 0.5133 - acc: 0.7755\n",
      "Epoch 12/25\n",
      "41888/41888 [==============================] - 13s 299us/step - loss: 0.5106 - acc: 0.7765\n",
      "Epoch 13/25\n",
      "41888/41888 [==============================] - 11s 256us/step - loss: 0.5074 - acc: 0.7788\n",
      "Epoch 14/25\n",
      "41888/41888 [==============================] - 13s 310us/step - loss: 0.5052 - acc: 0.7793\n",
      "Epoch 15/25\n",
      "41888/41888 [==============================] - 12s 294us/step - loss: 0.5014 - acc: 0.7817\n",
      "Epoch 16/25\n",
      "41888/41888 [==============================] - 13s 318us/step - loss: 0.4980 - acc: 0.7820\n",
      "Epoch 17/25\n",
      "41888/41888 [==============================] - 13s 312us/step - loss: 0.4959 - acc: 0.7854\n",
      "Epoch 18/25\n",
      "41888/41888 [==============================] - 27s 646us/step - loss: 0.4927 - acc: 0.7869\n",
      "Epoch 19/25\n",
      "41888/41888 [==============================] - 15s 366us/step - loss: 0.4891 - acc: 0.7861\n",
      "Epoch 20/25\n",
      "41888/41888 [==============================] - ETA: 0s - loss: 0.4857 - acc: 0.785 - 11s 272us/step - loss: 0.4857 - acc: 0.7859\n",
      "Epoch 21/25\n",
      "41888/41888 [==============================] - 12s 278us/step - loss: 0.4864 - acc: 0.7867\n",
      "Epoch 22/25\n",
      "41888/41888 [==============================] - 11s 263us/step - loss: 0.4822 - acc: 0.7898\n",
      "Epoch 23/25\n",
      "41888/41888 [==============================] - 13s 305us/step - loss: 0.4824 - acc: 0.7892\n",
      "Epoch 24/25\n",
      "41888/41888 [==============================] - 12s 296us/step - loss: 0.4785 - acc: 0.7897\n",
      "Epoch 25/25\n",
      "41888/41888 [==============================] - 13s 307us/step - loss: 0.4795 - acc: 0.7895\n",
      "350/350 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(best_model['conf'][0], input_shape=(input_dimension,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(best_model['conf'][4]))\n",
    "model.add(Dense(best_model['conf'][1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(best_model['conf'][4]))\n",
    "model.add(Dense(output_dimension))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "plot_model(model, to_file='./mlp-best-model.png', show_shapes=True)\n",
    "        \n",
    "\n",
    "# loss function for one-hot vector\n",
    "# use of adam optimizer\n",
    "# accuracy is a good metric for classification tasks\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train the network\n",
    "model_history = model.fit(x=x_train, y=y_train, batch_size=best_model['conf'][2], epochs=best_model['bepoch'])\n",
    "\n",
    "a,b = model.evaluate(x_test,y_test, batch_size=best_model['conf'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : Loss(0.47953168926027734) - Accuracy: (0.7894623758594347)\n"
     ]
    }
   ],
   "source": [
    "print ('Train : Loss(%s) - Accuracy: (%s)' %(model_history.history['loss'][-1],model_history.history['acc'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : Loss(0.49386654240744454) - Accuracy: (0.7999999989782061)\n"
     ]
    }
   ],
   "source": [
    "print ('Test : Loss(%s) - Accuracy: (%s)' %(a,b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
